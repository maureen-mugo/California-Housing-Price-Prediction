{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee61a233-29d3-4be1-9799-62e3dcbc4a03",
   "metadata": {},
   "source": [
    "This project creates a model that classifies handwritten 3s and 7s from the MNIST sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d96334-bd37-4dbb-9496-354c4a7472c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc7891a-99a9-402b-946a-43cc0f1125cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq fastbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08df2974-89ec-4707-b9b6-6d196497a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2155893f-dad1-4bdb-8873-9c5fa976bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae04ad3e-8614-4655-ae3f-28269b2576ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e21fb5-0dce-4654-8765-e4d956531df7",
   "metadata": {},
   "source": [
    ".BASE_PATH is an attribute to path that tells where the starting point is.  \n",
    "If you run 'path' it shows you where it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c510f8a-5a22-47b2-b574-d0eba845b208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949b9743-c5b5-45af-a937-01b60109b283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('train'),Path('labels.csv'),Path('valid')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b019ebf-1222-4b08-b21e-c5a3ce0394c3",
   "metadata": {},
   "source": [
    "This lets us see what is in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6aa642-d44a-4ca6-953a-4da9faf421f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathlib.PosixPath"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19805303-739c-4aaf-ace4-34a15c1d2151",
   "metadata": {},
   "source": [
    "pathlib is part of a Python standard library but doesn't have 'ls' command  so we have to add .ls. For instance path.ls()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6052cd1e-b8ff-4d10-a63b-f924a7f3b3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train/7'),Path('train/3')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d0b5c-0255-450b-a113-7a46383f78e2",
   "metadata": {},
   "source": [
    "This allows us to see what is in the train folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff4455f-6dea-40dd-a7db-6b6219724fff",
   "metadata": {},
   "source": [
    "3s and 7s are labels/targets in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3c6225-bde4-4a4d-ac1c-6712e6d79436",
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a350259a-595c-46aa-b218-ec4fb23cd84f",
   "metadata": {},
   "source": [
    "This allows us to sort the data so that it is consistent/ get the same order of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01b50ef6-86b2-4b2f-9246-0dbc461d0d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bfe6e62-525f-4057-81e6-e5b6ad7e19df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6265) [Path('train/7/10002.png'),Path('train/7/1001.png'),Path('train/7/10014.png'),Path('train/7/10019.png'),Path('train/7/10039.png'),Path('train/7/10046.png'),Path('train/7/10050.png'),Path('train/7/10063.png'),Path('train/7/10077.png'),Path('train/7/10086.png')...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sevens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb7e37c-d864-4f87-b9ac-c88cf411e53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_path = threes[1]\n",
    "im3 = Image.open(im3_path)\n",
    "im3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a56a1-b7ac-4d2d-b7c0-4583d762150b",
   "metadata": {},
   "source": [
    "This allows us to see one image from the 3s folder after sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c14dc8b-b93b-47ec-a1ea-fed43d45c3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.PngImagePlugin.PngImageFile"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(im3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddb304e-ddc9-4e9a-be13-d9abb53f5259",
   "metadata": {},
   "source": [
    "The im3 image is a png file.  \n",
    "We need to represent this in number format as everything is represented as numbers in computers.  \n",
    "To view the number that represent this image we convert it to a Numpy array or PyTorch tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b393ec-6d91-4d9d-b788-b6e8c3d4da9c",
   "metadata": {},
   "source": [
    "To convert it to a Numpy array:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5db64868-3bc7-4ea4-972a-1bbc14167fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  29],\n",
       "       [  0,   0,   0,  48, 166, 224],\n",
       "       [  0,  93, 244, 249, 253, 187],\n",
       "       [  0, 107, 253, 253, 230,  48],\n",
       "       [  0,   3,  20,  20,  15,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(im3)[4:10, 4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf74979c-9f1a-4339-bf78-9aa2d0acb6eb",
   "metadata": {},
   "source": [
    "This shows us an index of a number at the top left from 4 up to the number before 10. (It does not include 10).  \n",
    "[4:10, 4:10] represents [rows, columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e38865-3afb-496a-b7f4-9e1722164d7b",
   "metadata": {},
   "source": [
    "There are 8 bit integer, thus between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc41822-7840-4485-87f7-5cff34fabfc6",
   "metadata": {},
   "source": [
    "To convert to a PyTorch Tensor:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0303d9e-c4bc-4a5b-ac2c-429162314db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  29],\n",
       "        [  0,   0,   0,  48, 166, 224],\n",
       "        [  0,  93, 244, 249, 253, 187],\n",
       "        [  0, 107, 253, 253, 230,  48],\n",
       "        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(im3)[4:10, 4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab3179-a2a0-4f9a-a2f3-5820d6e437d1",
   "metadata": {},
   "source": [
    "PyTorch tensors and Numpy arrays behave the same but PyToch tensors can be computed on GPU and not onlu in CPUs like numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47553d89-035b-47dd-bd9b-ca90d3ed7c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_60330_row0_col0, #T_60330_row0_col1, #T_60330_row0_col2, #T_60330_row0_col3, #T_60330_row0_col4, #T_60330_row0_col5, #T_60330_row0_col6, #T_60330_row0_col7, #T_60330_row0_col8, #T_60330_row0_col9, #T_60330_row0_col10, #T_60330_row0_col11, #T_60330_row0_col12, #T_60330_row0_col13, #T_60330_row0_col14, #T_60330_row0_col15, #T_60330_row0_col16, #T_60330_row0_col17, #T_60330_row1_col0, #T_60330_row1_col1, #T_60330_row1_col2, #T_60330_row1_col3, #T_60330_row1_col4, #T_60330_row1_col15, #T_60330_row1_col16, #T_60330_row1_col17, #T_60330_row2_col0, #T_60330_row2_col1, #T_60330_row2_col2, #T_60330_row2_col15, #T_60330_row2_col16, #T_60330_row2_col17, #T_60330_row3_col0, #T_60330_row3_col15, #T_60330_row3_col16, #T_60330_row3_col17, #T_60330_row4_col0, #T_60330_row4_col6, #T_60330_row4_col7, #T_60330_row4_col8, #T_60330_row4_col9, #T_60330_row4_col10, #T_60330_row4_col15, #T_60330_row4_col16, #T_60330_row4_col17, #T_60330_row5_col0, #T_60330_row5_col5, #T_60330_row5_col6, #T_60330_row5_col7, #T_60330_row5_col8, #T_60330_row5_col9, #T_60330_row5_col15, #T_60330_row5_col16, #T_60330_row5_col17, #T_60330_row6_col0, #T_60330_row6_col1, #T_60330_row6_col2, #T_60330_row6_col3, #T_60330_row6_col4, #T_60330_row6_col5, #T_60330_row6_col6, #T_60330_row6_col7, #T_60330_row6_col8, #T_60330_row6_col9, #T_60330_row6_col14, #T_60330_row6_col15, #T_60330_row6_col16, #T_60330_row6_col17, #T_60330_row7_col0, #T_60330_row7_col1, #T_60330_row7_col2, #T_60330_row7_col3, #T_60330_row7_col4, #T_60330_row7_col5, #T_60330_row7_col6, #T_60330_row7_col13, #T_60330_row7_col14, #T_60330_row7_col15, #T_60330_row7_col16, #T_60330_row7_col17, #T_60330_row8_col0, #T_60330_row8_col1, #T_60330_row8_col2, #T_60330_row8_col3, #T_60330_row8_col4, #T_60330_row8_col13, #T_60330_row8_col14, #T_60330_row8_col15, #T_60330_row8_col16, #T_60330_row8_col17, #T_60330_row9_col0, #T_60330_row9_col1, #T_60330_row9_col2, #T_60330_row9_col3, #T_60330_row9_col4, #T_60330_row9_col16, #T_60330_row9_col17, #T_60330_row10_col0, #T_60330_row10_col1, #T_60330_row10_col2, #T_60330_row10_col3, #T_60330_row10_col4, #T_60330_row10_col5, #T_60330_row10_col6, #T_60330_row10_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row1_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #efefef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row1_col6, #T_60330_row1_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #7c7c7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row1_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4a4a4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row1_col8, #T_60330_row1_col9, #T_60330_row1_col10, #T_60330_row2_col5, #T_60330_row2_col6, #T_60330_row2_col7, #T_60330_row2_col11, #T_60330_row2_col12, #T_60330_row2_col13, #T_60330_row3_col4, #T_60330_row3_col12, #T_60330_row3_col13, #T_60330_row4_col1, #T_60330_row4_col2, #T_60330_row4_col3, #T_60330_row4_col12, #T_60330_row4_col13, #T_60330_row5_col12, #T_60330_row6_col11, #T_60330_row9_col11, #T_60330_row10_col11, #T_60330_row10_col12, #T_60330_row10_col13, #T_60330_row10_col14, #T_60330_row10_col15, #T_60330_row10_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row1_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #606060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row1_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4d4d4d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row1_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bbbbbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row2_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e4e4e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row2_col4, #T_60330_row8_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #6b6b6b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row2_col8, #T_60330_row2_col14, #T_60330_row3_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #171717;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row2_col9, #T_60330_row3_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4b4b4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row2_col10, #T_60330_row7_col10, #T_60330_row8_col8, #T_60330_row8_col10, #T_60330_row9_col8, #T_60330_row9_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #010101;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row3_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #272727;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row3_col2 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #0a0a0a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row3_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #050505;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row3_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #333333;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row3_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e6e6e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row3_col7, #T_60330_row3_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fafafa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row3_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fbfbfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row3_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fdfdfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row4_col4 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1b1b1b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row4_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e0e0e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row4_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4e4e4e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row4_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #767676;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row5_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fcfcfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row5_col2, #T_60330_row5_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f6f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row5_col4, #T_60330_row7_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f8f8f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row5_col10, #T_60330_row10_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e8e8e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row5_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #222222;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row5_col13, #T_60330_row6_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #090909;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row5_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d0d0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row6_col10, #T_60330_row7_col11, #T_60330_row9_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #060606;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row6_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #979797;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row7_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #b6b6b6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row7_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #252525;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row7_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #999999;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row8_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f9f9f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row8_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #101010;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row8_col9, #T_60330_row9_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #020202;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row8_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #545454;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row8_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f1f1f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row9_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f7f7f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row9_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #030303;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row9_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #181818;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row9_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #303030;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row9_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #a9a9a9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_60330_row9_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fefefe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row10_col8, #T_60330_row10_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bababa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_60330_row10_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #393939;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_60330\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_60330_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_60330_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_60330_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_60330_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_60330_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_60330_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "      <th id=\"T_60330_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
       "      <th id=\"T_60330_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
       "      <th id=\"T_60330_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
       "      <th id=\"T_60330_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
       "      <th id=\"T_60330_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
       "      <th id=\"T_60330_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
       "      <th id=\"T_60330_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
       "      <th id=\"T_60330_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
       "      <th id=\"T_60330_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n",
       "      <th id=\"T_60330_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n",
       "      <th id=\"T_60330_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n",
       "      <th id=\"T_60330_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_60330_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_60330_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_60330_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_60330_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_60330_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_60330_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_60330_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_60330_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_60330_row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "      <td id=\"T_60330_row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "      <td id=\"T_60330_row0_col9\" class=\"data row0 col9\" >0</td>\n",
       "      <td id=\"T_60330_row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "      <td id=\"T_60330_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "      <td id=\"T_60330_row0_col12\" class=\"data row0 col12\" >0</td>\n",
       "      <td id=\"T_60330_row0_col13\" class=\"data row0 col13\" >0</td>\n",
       "      <td id=\"T_60330_row0_col14\" class=\"data row0 col14\" >0</td>\n",
       "      <td id=\"T_60330_row0_col15\" class=\"data row0 col15\" >0</td>\n",
       "      <td id=\"T_60330_row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "      <td id=\"T_60330_row0_col17\" class=\"data row0 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60330_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_60330_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_60330_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_60330_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_60330_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_60330_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_60330_row1_col5\" class=\"data row1 col5\" >29</td>\n",
       "      <td id=\"T_60330_row1_col6\" class=\"data row1 col6\" >150</td>\n",
       "      <td id=\"T_60330_row1_col7\" class=\"data row1 col7\" >195</td>\n",
       "      <td id=\"T_60330_row1_col8\" class=\"data row1 col8\" >254</td>\n",
       "      <td id=\"T_60330_row1_col9\" class=\"data row1 col9\" >255</td>\n",
       "      <td id=\"T_60330_row1_col10\" class=\"data row1 col10\" >254</td>\n",
       "      <td id=\"T_60330_row1_col11\" class=\"data row1 col11\" >176</td>\n",
       "      <td id=\"T_60330_row1_col12\" class=\"data row1 col12\" >193</td>\n",
       "      <td id=\"T_60330_row1_col13\" class=\"data row1 col13\" >150</td>\n",
       "      <td id=\"T_60330_row1_col14\" class=\"data row1 col14\" >96</td>\n",
       "      <td id=\"T_60330_row1_col15\" class=\"data row1 col15\" >0</td>\n",
       "      <td id=\"T_60330_row1_col16\" class=\"data row1 col16\" >0</td>\n",
       "      <td id=\"T_60330_row1_col17\" class=\"data row1 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60330_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_60330_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_60330_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_60330_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_60330_row2_col3\" class=\"data row2 col3\" >48</td>\n",
       "      <td id=\"T_60330_row2_col4\" class=\"data row2 col4\" >166</td>\n",
       "      <td id=\"T_60330_row2_col5\" class=\"data row2 col5\" >224</td>\n",
       "      <td id=\"T_60330_row2_col6\" class=\"data row2 col6\" >253</td>\n",
       "      <td id=\"T_60330_row2_col7\" class=\"data row2 col7\" >253</td>\n",
       "      <td id=\"T_60330_row2_col8\" class=\"data row2 col8\" >234</td>\n",
       "      <td id=\"T_60330_row2_col9\" class=\"data row2 col9\" >196</td>\n",
       "      <td id=\"T_60330_row2_col10\" class=\"data row2 col10\" >253</td>\n",
       "      <td id=\"T_60330_row2_col11\" class=\"data row2 col11\" >253</td>\n",
       "      <td id=\"T_60330_row2_col12\" class=\"data row2 col12\" >253</td>\n",
       "      <td id=\"T_60330_row2_col13\" class=\"data row2 col13\" >253</td>\n",
       "      <td id=\"T_60330_row2_col14\" class=\"data row2 col14\" >233</td>\n",
       "      <td id=\"T_60330_row2_col15\" class=\"data row2 col15\" >0</td>\n",
       "      <td id=\"T_60330_row2_col16\" class=\"data row2 col16\" >0</td>\n",
       "      <td id=\"T_60330_row2_col17\" class=\"data row2 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60330_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_60330_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_60330_row3_col1\" class=\"data row3 col1\" >93</td>\n",
       "      <td id=\"T_60330_row3_col2\" class=\"data row3 col2\" >244</td>\n",
       "      <td id=\"T_60330_row3_col3\" class=\"data row3 col3\" >249</td>\n",
       "      <td id=\"T_60330_row3_col4\" class=\"data row3 col4\" >253</td>\n",
       "      <td id=\"T_60330_row3_col5\" class=\"data row3 col5\" >187</td>\n",
       "      <td id=\"T_60330_row3_col6\" class=\"data row3 col6\" >46</td>\n",
       "      <td id=\"T_60330_row3_col7\" class=\"data row3 col7\" >10</td>\n",
       "      <td id=\"T_60330_row3_col8\" class=\"data row3 col8\" >8</td>\n",
       "      <td id=\"T_60330_row3_col9\" class=\"data row3 col9\" >4</td>\n",
       "      <td id=\"T_60330_row3_col10\" class=\"data row3 col10\" >10</td>\n",
       "      <td id=\"T_60330_row3_col11\" class=\"data row3 col11\" >194</td>\n",
       "      <td id=\"T_60330_row3_col12\" class=\"data row3 col12\" >253</td>\n",
       "      <td id=\"T_60330_row3_col13\" class=\"data row3 col13\" >253</td>\n",
       "      <td id=\"T_60330_row3_col14\" class=\"data row3 col14\" >233</td>\n",
       "      <td id=\"T_60330_row3_col15\" class=\"data row3 col15\" >0</td>\n",
       "      <td id=\"T_60330_row3_col16\" class=\"data row3 col16\" >0</td>\n",
       "      <td id=\"T_60330_row3_col17\" class=\"data row3 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60330_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_60330_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_60330_row4_col1\" class=\"data row4 col1\" >107</td>\n",
       "      <td id=\"T_60330_row4_col2\" class=\"data row4 col2\" >253</td>\n",
       "      <td id=\"T_60330_row4_col3\" class=\"data row4 col3\" >253</td>\n",
       "      <td id=\"T_60330_row4_col4\" class=\"data row4 col4\" >230</td>\n",
       "      <td id=\"T_60330_row4_col5\" class=\"data row4 col5\" >48</td>\n",
       "      <td id=\"T_60330_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "      <td id=\"T_60330_row4_col7\" class=\"data row4 col7\" >0</td>\n",
       "      <td id=\"T_60330_row4_col8\" class=\"data row4 col8\" >0</td>\n",
       "      <td id=\"T_60330_row4_col9\" class=\"data row4 col9\" >0</td>\n",
       "      <td id=\"T_60330_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "      <td id=\"T_60330_row4_col11\" class=\"data row4 col11\" >192</td>\n",
       "      <td id=\"T_60330_row4_col12\" class=\"data row4 col12\" >253</td>\n",
       "      <td id=\"T_60330_row4_col13\" class=\"data row4 col13\" >253</td>\n",
       "      <td id=\"T_60330_row4_col14\" class=\"data row4 col14\" >156</td>\n",
       "      <td id=\"T_60330_row4_col15\" class=\"data row4 col15\" >0</td>\n",
       "      <td id=\"T_60330_row4_col16\" class=\"data row4 col16\" >0</td>\n",
       "      <td id=\"T_60330_row4_col17\" class=\"data row4 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60330_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_60330_row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "      <td id=\"T_60330_row5_col1\" class=\"data row5 col1\" >3</td>\n",
       "      <td id=\"T_60330_row5_col2\" class=\"data row5 col2\" >20</td>\n",
       "      <td id=\"T_60330_row5_col3\" class=\"data row5 col3\" >20</td>\n",
       "      <td id=\"T_60330_row5_col4\" class=\"data row5 col4\" >15</td>\n",
       "      <td id=\"T_60330_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_60330_row5_col6\" class=\"data row5 col6\" >0</td>\n",
       "      <td id=\"T_60330_row5_col7\" class=\"data row5 col7\" >0</td>\n",
       "      <td id=\"T_60330_row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "      <td id=\"T_60330_row5_col9\" class=\"data row5 col9\" >0</td>\n",
       "      <td id=\"T_60330_row5_col10\" class=\"data row5 col10\" >43</td>\n",
       "      <td id=\"T_60330_row5_col11\" class=\"data row5 col11\" >224</td>\n",
       "      <td id=\"T_60330_row5_col12\" class=\"data row5 col12\" >253</td>\n",
       "      <td id=\"T_60330_row5_col13\" class=\"data row5 col13\" >245</td>\n",
       "      <td id=\"T_60330_row5_col14\" class=\"data row5 col14\" >74</td>\n",
       "      <td id=\"T_60330_row5_col15\" class=\"data row5 col15\" >0</td>\n",
       "      <td id=\"T_60330_row5_col16\" class=\"data row5 col16\" >0</td>\n",
       "      <td id=\"T_60330_row5_col17\" class=\"data row5 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60330_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_60330_row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "      <td id=\"T_60330_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_60330_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_60330_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_60330_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_60330_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_60330_row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "      <td id=\"T_60330_row6_col7\" class=\"data row6 col7\" >0</td>\n",
       "      <td id=\"T_60330_row6_col8\" class=\"data row6 col8\" >0</td>\n",
       "      <td id=\"T_60330_row6_col9\" class=\"data row6 col9\" >0</td>\n",
       "      <td id=\"T_60330_row6_col10\" class=\"data row6 col10\" >249</td>\n",
       "      <td id=\"T_60330_row6_col11\" class=\"data row6 col11\" >253</td>\n",
       "      <td id=\"T_60330_row6_col12\" class=\"data row6 col12\" >245</td>\n",
       "      <td id=\"T_60330_row6_col13\" class=\"data row6 col13\" >126</td>\n",
       "      <td id=\"T_60330_row6_col14\" class=\"data row6 col14\" >0</td>\n",
       "      <td id=\"T_60330_row6_col15\" class=\"data row6 col15\" >0</td>\n",
       "      <td id=\"T_60330_row6_col16\" class=\"data row6 col16\" >0</td>\n",
       "      <td id=\"T_60330_row6_col17\" class=\"data row6 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60330_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_60330_row7_col0\" class=\"data row7 col0\" >0</td>\n",
       "      <td id=\"T_60330_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_60330_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_60330_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "      <td id=\"T_60330_row7_col4\" class=\"data row7 col4\" >0</td>\n",
       "      <td id=\"T_60330_row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "      <td id=\"T_60330_row7_col6\" class=\"data row7 col6\" >0</td>\n",
       "      <td id=\"T_60330_row7_col7\" class=\"data row7 col7\" >14</td>\n",
       "      <td id=\"T_60330_row7_col8\" class=\"data row7 col8\" >101</td>\n",
       "      <td id=\"T_60330_row7_col9\" class=\"data row7 col9\" >223</td>\n",
       "      <td id=\"T_60330_row7_col10\" class=\"data row7 col10\" >253</td>\n",
       "      <td id=\"T_60330_row7_col11\" class=\"data row7 col11\" >248</td>\n",
       "      <td id=\"T_60330_row7_col12\" class=\"data row7 col12\" >124</td>\n",
       "      <td id=\"T_60330_row7_col13\" class=\"data row7 col13\" >0</td>\n",
       "      <td id=\"T_60330_row7_col14\" class=\"data row7 col14\" >0</td>\n",
       "      <td id=\"T_60330_row7_col15\" class=\"data row7 col15\" >0</td>\n",
       "      <td id=\"T_60330_row7_col16\" class=\"data row7 col16\" >0</td>\n",
       "      <td id=\"T_60330_row7_col17\" class=\"data row7 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60330_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_60330_row8_col0\" class=\"data row8 col0\" >0</td>\n",
       "      <td id=\"T_60330_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_60330_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_60330_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "      <td id=\"T_60330_row8_col4\" class=\"data row8 col4\" >0</td>\n",
       "      <td id=\"T_60330_row8_col5\" class=\"data row8 col5\" >11</td>\n",
       "      <td id=\"T_60330_row8_col6\" class=\"data row8 col6\" >166</td>\n",
       "      <td id=\"T_60330_row8_col7\" class=\"data row8 col7\" >239</td>\n",
       "      <td id=\"T_60330_row8_col8\" class=\"data row8 col8\" >253</td>\n",
       "      <td id=\"T_60330_row8_col9\" class=\"data row8 col9\" >253</td>\n",
       "      <td id=\"T_60330_row8_col10\" class=\"data row8 col10\" >253</td>\n",
       "      <td id=\"T_60330_row8_col11\" class=\"data row8 col11\" >187</td>\n",
       "      <td id=\"T_60330_row8_col12\" class=\"data row8 col12\" >30</td>\n",
       "      <td id=\"T_60330_row8_col13\" class=\"data row8 col13\" >0</td>\n",
       "      <td id=\"T_60330_row8_col14\" class=\"data row8 col14\" >0</td>\n",
       "      <td id=\"T_60330_row8_col15\" class=\"data row8 col15\" >0</td>\n",
       "      <td id=\"T_60330_row8_col16\" class=\"data row8 col16\" >0</td>\n",
       "      <td id=\"T_60330_row8_col17\" class=\"data row8 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60330_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_60330_row9_col0\" class=\"data row9 col0\" >0</td>\n",
       "      <td id=\"T_60330_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "      <td id=\"T_60330_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_60330_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_60330_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "      <td id=\"T_60330_row9_col5\" class=\"data row9 col5\" >16</td>\n",
       "      <td id=\"T_60330_row9_col6\" class=\"data row9 col6\" >248</td>\n",
       "      <td id=\"T_60330_row9_col7\" class=\"data row9 col7\" >250</td>\n",
       "      <td id=\"T_60330_row9_col8\" class=\"data row9 col8\" >253</td>\n",
       "      <td id=\"T_60330_row9_col9\" class=\"data row9 col9\" >253</td>\n",
       "      <td id=\"T_60330_row9_col10\" class=\"data row9 col10\" >253</td>\n",
       "      <td id=\"T_60330_row9_col11\" class=\"data row9 col11\" >253</td>\n",
       "      <td id=\"T_60330_row9_col12\" class=\"data row9 col12\" >232</td>\n",
       "      <td id=\"T_60330_row9_col13\" class=\"data row9 col13\" >213</td>\n",
       "      <td id=\"T_60330_row9_col14\" class=\"data row9 col14\" >111</td>\n",
       "      <td id=\"T_60330_row9_col15\" class=\"data row9 col15\" >2</td>\n",
       "      <td id=\"T_60330_row9_col16\" class=\"data row9 col16\" >0</td>\n",
       "      <td id=\"T_60330_row9_col17\" class=\"data row9 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60330_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_60330_row10_col0\" class=\"data row10 col0\" >0</td>\n",
       "      <td id=\"T_60330_row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "      <td id=\"T_60330_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_60330_row10_col3\" class=\"data row10 col3\" >0</td>\n",
       "      <td id=\"T_60330_row10_col4\" class=\"data row10 col4\" >0</td>\n",
       "      <td id=\"T_60330_row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "      <td id=\"T_60330_row10_col6\" class=\"data row10 col6\" >0</td>\n",
       "      <td id=\"T_60330_row10_col7\" class=\"data row10 col7\" >43</td>\n",
       "      <td id=\"T_60330_row10_col8\" class=\"data row10 col8\" >98</td>\n",
       "      <td id=\"T_60330_row10_col9\" class=\"data row10 col9\" >98</td>\n",
       "      <td id=\"T_60330_row10_col10\" class=\"data row10 col10\" >208</td>\n",
       "      <td id=\"T_60330_row10_col11\" class=\"data row10 col11\" >253</td>\n",
       "      <td id=\"T_60330_row10_col12\" class=\"data row10 col12\" >253</td>\n",
       "      <td id=\"T_60330_row10_col13\" class=\"data row10 col13\" >253</td>\n",
       "      <td id=\"T_60330_row10_col14\" class=\"data row10 col14\" >253</td>\n",
       "      <td id=\"T_60330_row10_col15\" class=\"data row10 col15\" >187</td>\n",
       "      <td id=\"T_60330_row10_col16\" class=\"data row10 col16\" >22</td>\n",
       "      <td id=\"T_60330_row10_col17\" class=\"data row10 col17\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe7f02c8520>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_t = tensor(im3)\n",
    "df = pd.DataFrame(im3_t[4:15, 4:22])\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9362f81c-a3f1-4e10-9b29-0bece2835c41",
   "metadata": {},
   "source": [
    "im3_t = tensor(im3) -> grabs im3 and turns it to a tensor.  \n",
    "df = pd.DataFrame(im3_t[4:15, 4:22]) -> grabs part of the image, that is [4:15, 4:22]  \n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys') -> turns it to a panda's dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59059b66-8d84-4760-aad0-fa2f3a535e3d",
   "metadata": {},
   "source": [
    "Reason for turning it to a panda dataframe is because panda's dataframe has a convenient thing called background_gradient() that turns a background into a gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5efd5-46a5-422d-886b-b5c9b1b330b3",
   "metadata": {},
   "source": [
    "In the output, 0s are the whites and 255 are the blacks. Then there are shades of grey that vary between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b61d06f-ebe0-4898-b68f-5e11d38a528a",
   "metadata": {},
   "source": [
    "## Creating a model that detects a 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bbb9df-b422-4073-8ba5-0b82f31cf5ee",
   "metadata": {},
   "source": [
    "Idea is, if it doesn't recognise that a number is a 3, then it must be a 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed61c0-f901-4991-8b15-56aac5c73cdd",
   "metadata": {},
   "source": [
    "### Pixel Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebabda68-816b-4da9-adff-b72a91ef1d27",
   "metadata": {},
   "source": [
    "- Find the average pixel value forevery pixe; of the threes and sevens.  \n",
    "- The two group averages define the \"ideal\" 3 and 7.  \n",
    "- Then to classify an image as a digit, we see which of these two ideal digits the image is similar to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c941399-bee6-43d1-8643-890a62a7942a",
   "metadata": {},
   "source": [
    "#### Create a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c24ce47-79f0-4ca5-84e4-ed959090a731",
   "metadata": {},
   "source": [
    "Baseline model -> a simple model which you are confident that it can perform reasonably well, should be simple to implement and easy to test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abcdeac-5804-4d4b-bd5f-f44b741879a3",
   "metadata": {},
   "source": [
    "First, we need to list all the images of sevens and threes as tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "776fab85-fa5f-4fe3-9fe3-4e17cc728e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "len(three_tensors), len(seven_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a7f63c8-0f04-4e84-b92c-686c8c7afb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(three_tensors[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d60a252-995b-4090-a651-47437a041381",
   "metadata": {},
   "source": [
    "We can now display one of the 3s in the three_tensor list.  \n",
    "Remember, this is a tensor and not a PIL image as we had seen before. Jupyter doesn't know how to display tensor so we use show_image()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a07f9-aabf-4b4d-9646-d7e6673dec5f",
   "metadata": {},
   "source": [
    "We now need to get the average of all those 3s and 7s.  \n",
    "First we need to change three_tensors and seven_tensors from lists, which can't easily do mathematical computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7021a774-6f33-43ac-86ea-e7acd960a1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seven_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f9595-773b-4f12-a094-d44b0cda7b1a",
   "metadata": {},
   "source": [
    "So we first stack all these 28×28 pixels images on top of each other to create like a 3D cube of images, quite like a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10bce12d-161c-465c-b3d8-4c9444496e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1cc369-f7b0-4f7e-b21f-b9aff17b1447",
   "metadata": {},
   "source": [
    "This turns the list to a tensor so the shape is now 6131 by 28 by 28.  \n",
    "More like a cube of height 6131 that is 28×28."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70133aa5-2323-453e-b467-6525cefae115",
   "metadata": {},
   "source": [
    "Now if we are going to find the mean, we need to change them to floating point values because we don't want to kind of have integers rounding off.  \n",
    "Also, its kind of a standard in computer vision that when you are working with floats, expect them to be between 0 and 1, so we divide by 255 because they are between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a35b51d-34c0-4fd5-af91-ad4b25f29b06",
   "metadata": {},
   "source": [
    "The output is a Rank 3 tensor as it has three axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdb5215a-9823-4af8-995e-67f1b61ff26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stacked_threes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3445ed61-3d08-4efa-aa5e-81aa84cd943a",
   "metadata": {},
   "source": [
    "We can also get it from 'ndim' that stands for number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55401832-9e64-4362-b641-471693a9066e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50974b-2a88-4aeb-886d-bcd9864f8535",
   "metadata": {},
   "source": [
    "Numpy tends to call it axis, PyTorch tends to call it dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0d7fe-693f-4366-8c99-133b2e4aae23",
   "metadata": {},
   "source": [
    "Rank -> Number of axes or dimensions in a tensor.  \n",
    "Shape -> Size of each axis of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b4e3d22-c903-4abf-93e9-7525b4c8b415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean3 = stacked_threes.mean(0)\n",
    "show_image(mean3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3748dc-6357-41c2-8ae8-b56e3be4d1d9",
   "metadata": {},
   "source": [
    "This gives us the mean of just the 0 axis, that is the mean across the images.  \n",
    "Takes the mean across the 6131 axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80105f57-7244-4cd0-81d0-8254fb851e86",
   "metadata": {},
   "source": [
    "When we show the image, we get the 'ideal' 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d792b9-5ba2-4565-bc82-62b457264dcc",
   "metadata": {},
   "source": [
    "Now we, we can do the same for 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe4f154-61f0-4a91-b4ce-c2f48ae769a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean7 = stacked_sevens.mean(0)\n",
    "show_image(mean7);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd2a2cf-b5a3-46fc-b2a9-fe639c7444f3",
   "metadata": {},
   "source": [
    "This shows us the 'ideal' 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133e85d-a6d8-4064-b8a6-f09d3f68a8d4",
   "metadata": {},
   "source": [
    "Now, let's grab a 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1258f751-dd93-4c51-8727-47c9c734690b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_3 = stacked_threes[1]\n",
    "show_image(a_3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6dbb7-610f-4c2e-a1e5-6564e43fdfe0",
   "metadata": {},
   "source": [
    "We can find if the a_3 is similar to the 'ideal' 3 or 7.  \n",
    "The one that is more similar to, that's the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4078ab-1f4f-4b59-89d3-8362906be2ae",
   "metadata": {},
   "source": [
    "We just can't add up the difference between the pixel of the image and the ideal digit because some differences will be negative and some will be positive and they'll cancel out. This will result in an image thats too dark in some places and too light in others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e339a-0afc-4a9d-b4d2-2279ec662960",
   "metadata": {},
   "source": [
    "To avoid this, we have to make them all positive values.  \n",
    "This can be achieved by:  \n",
    "1) Finding the absolute values (simply means removing the minus sign), the take the average. This is called the Mean Absolute Difference or L1 norm.  \n",
    "2) Take the square of each difference and the take the mean then find the square root to undo the squaring. This is called Root Mean Squared Error or L2 norm.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bc5438f-1430-4c5d-8ee2-131d2701d629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1114), tensor(0.2021))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_3_abs = (a_3-mean3).abs().mean()\n",
    "dist_3_sqr = ((a_3-mean3)**2).mean().sqrt()\n",
    "dist_3_abs, dist_3_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3570d2de-f8ca-4312-b613-7a0707f7bb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_7_abs = (a_3-mean7).abs().mean()\n",
    "dist_7_sqr = ((a_3-mean7)**2).mean().sqrt()\n",
    "dist_7_abs, dist_7_sqr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf919fa8-f610-44f9-aff0-e782e9c8b1f4",
   "metadata": {},
   "source": [
    "We do for both 3 and 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b732b7c8-bbe3-4e53-8596-04755b386407",
   "metadata": {},
   "source": [
    "The distance in terms of absolute from mean of 3 is 0.114 and mean of 7 is 0.1586 so its close to the mean of 3 than the mean of 7. Therefore, we can guess that its a 3 based on the mean absolute differences.  \n",
    "This is same for the root mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb6ef3-6c07-4359-86d2-3d029f51ac82",
   "metadata": {},
   "source": [
    "In the codes above, we don't have to write  minus abs() mean(), we can use L1_loss.  \n",
    "Also, we don't have to write minus squared, we can write mse_loss, but it doesn't do the square root so we have to include .sqrt()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85040cf0-1712-4292-8eab-35d79b75c1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.l1_loss(a_3.float(),mean7), F.mse_loss(a_3, mean7).sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37288788-ba97-4ee8-a630-d47d08f97eea",
   "metadata": {},
   "source": [
    "This can be found inside 'torch.nn.functional', which PyTorch recommends importing as F."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e6d292-3784-4662-9f63-2327c6e3eebf",
   "metadata": {},
   "source": [
    "##### Numpy array and PyTorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f916818c-2133-4130-8226-3e752108c8f0",
   "metadata": {},
   "source": [
    "To create an array or tensor, we can pass a list or lists or list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "007d74c6-79ff-4501-80ef-35bf72d6066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2, 3], [4, 5, 6]]\n",
    "arr = array(data)\n",
    "tns = tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e622176-bffa-4ee3-a6b0-7e90ce8227ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for numpy\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "820a60e2-c299-4c53-b407-9dcbe9884bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for PyTorch\n",
    "tns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba00ca-0df8-4a69-ae32-1918d2fa1327",
   "metadata": {},
   "source": [
    "To select a row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc54b85a-23d1-402a-8d11-b89da8ce4c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c3c583-dff9-4317-960c-4574f22785cb",
   "metadata": {},
   "source": [
    "To select a column:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2546e71c-83d4-446b-87fd-7c8132852313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b13ce64-93f9-4499-b27b-c91c4b06b864",
   "metadata": {},
   "source": [
    ": means row because its in the fist spot so therefore ,: is the same as removing it.  \n",
    "example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86bfa3c3-e8c3-4f13-97fb-189b554b6c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b6fd4-1451-46ba-b812-3a002ebb2354",
   "metadata": {},
   "source": [
    "Is the same as,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be2c7f85-f7ff-4b20-ad91-68801c86fdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a244ed-1184-47fe-8b6d-7bbb9a6924cc",
   "metadata": {},
   "source": [
    "Combining the together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d98dca2a-1021-476e-9fc7-7ebeb32bdf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4e3f7-e2a2-4bcb-be07-b1ad0144e85c",
   "metadata": {},
   "source": [
    "This gives the first row and everything from the first up to but not including the third column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f280038-da43-48cc-825a-c6049109edac",
   "metadata": {
    "tags": []
   },
   "source": [
    "[start:end] -> means from start to end but not including end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e3bb3-d09b-45dc-8d8b-7ec1e9f46f1a",
   "metadata": {},
   "source": [
    "Using standard operators to add all elements by 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da6aa45b-3dec-4627-a3c0-2aaa2a609eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4],\n",
       "        [5, 6, 7]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde3d8a-aad3-4567-b860-9e7b3efea3de",
   "metadata": {},
   "source": [
    "Finding the type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3afed107-4023-4500-bd25-9cb02e67bc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebddcdb7-5d39-481c-9129-35e66296ea91",
   "metadata": {},
   "source": [
    "Multiplying by a float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66766d19-743d-4e1d-a35b-2b0ce3df3ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5000, 3.0000, 4.5000],\n",
       "        [6.0000, 7.5000, 9.0000]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns*1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a9603-d7b9-49b6-aa43-72d4f4f7d4a7",
   "metadata": {},
   "source": [
    "Tensor automatically changes from a int to a float."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294476aa-e4ba-4ca7-8a25-b39fcbcf10e2",
   "metadata": {},
   "source": [
    "### Computing metrics using broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d699dd02-b3ff-4336-960c-9c0eb3011824",
   "metadata": {},
   "source": [
    "Is our model good enough?  \n",
    "To quantify this, we must define a metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc2437-5928-453d-8732-5eb5036a78ac",
   "metadata": {},
   "source": [
    "Metric -> a number which is calculated from the predictions of our model and the correct labels in our dataset, in order to tell us how good our model is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08883a30-80c5-44a4-8099-53193bc9092a",
   "metadata": {},
   "source": [
    "We ought to check our model is by calculating the metric, using our validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb2e84-1934-44db-b8f1-3876ecb403f9",
   "metadata": {},
   "source": [
    "First, lets create a tensor of our threes and sevens from our valid directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a544cf-d52f-4cbd-9670-fe57b00eb516",
   "metadata": {},
   "source": [
    "The following code does the similar process as what we had done in our training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8f2d498-564f-444a-a759-aa145634a276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_tens = torch.stack([tensor(Image.open(o))\n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o))\n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "valid_3_tens.shape, valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a15fae-6ecf-4462-a79f-5bae4a54800d",
   "metadata": {},
   "source": [
    "The code goes through through everything in the validation set of 3.ls() opens and turns them into a tensor then stacks them all up. Next, it turns them into a float by dividing by 255.  \n",
    "Same is done for the 7 folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07b4b7-f5c0-4be6-9912-921cf63fc19a",
   "metadata": {},
   "source": [
    "Then we check the shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4347a7f-28d6-427f-b415-959da6cd0920",
   "metadata": {},
   "source": [
    "Idea is, we want to create a function is_3 that will return true if we think something is a 3. So we have to check whether the digit we are testing on is closer to the 'ideal' three or seven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c7fc9-62b5-4382-867f-33157762373f",
   "metadata": {},
   "source": [
    "Let's create a function that takes the difference between two things, takes the absolute value and then takes the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "586126ba-ea74-4422-861b-b77382c666fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1114)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_distance(a, b): return (a-b).abs().mean((-1, -2))\n",
    "mnist_distance(a_3, mean3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f7a78-8934-4a05-bf93-576d19244ee6",
   "metadata": {},
   "source": [
    "The mnist_distance function takes the difference between two tensors, takes their absolute value then takes the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c9bfb-16e1-481a-8966-5bc809e20e1d",
   "metadata": {},
   "source": [
    "mean((-1,-2)) -> takes the mean of the last and the second last dimension.  \n",
    "This is going to take the mean of kind of the x and y axes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c872ba02-18d8-4095-85a8-dae2f5a2762d",
   "metadata": {},
   "source": [
    "It returns a single number which is the distance a_3 from the mean3. This is the same value as we got earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a0c50-53eb-4bd5-b1af-bb7f55e2065e",
   "metadata": {},
   "source": [
    "We need to do this for every image in the validation set so as to find the overall metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aee0d42b-a234-4aef-800e-a8418dd2d393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1328, 0.1523, 0.1245,  ..., 0.1383, 0.1280, 0.1138]),\n",
       " torch.Size([1010]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_dist = mnist_distance(valid_3_tens, mean3)\n",
    "valid_3_dist, valid_3_dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa4a51-35b5-44bb-8156-45ae9bd3de48",
   "metadata": {},
   "source": [
    "Broadcasting is a magic trick of Python that allows us to pass the whole validation set against the mean3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9e2102-facc-4d1e-b56b-87a205af2223",
   "metadata": {},
   "source": [
    "In our case, it returns 1010 numbers.  \n",
    "Here, we are doing a-b on the 1010 images on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41e8f425-c6f3-4338-8563-b4c9526b274a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1010, 28, 28])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_tens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36dd95-cf9a-4ccb-9ac1-273d254f9be3",
   "metadata": {},
   "source": [
    "Gives us a Rank 3 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e47bd60-3e89-499d-b594-ba71386d2622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4e11c7-c0c2-4a68-a02e-c2dd7fb40af1",
   "metadata": {},
   "source": [
    "Gives us a Rank 2 tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc518e6-aeab-4ea5-9cfa-c012161955ae",
   "metadata": {},
   "source": [
    "Broadcasting means if the two shapes don't match, if they matched it would just subtract every corresponding item. But because they don't match it actually acts as if there is 1010 versions of 28×28 (tensor of mean3). So its actually going to subtract this from every single one of mean3 tensor from every tensor of the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65da0b2-839c-4bda-b051-c595e02e7d02",
   "metadata": {},
   "source": [
    "Broadcating requires us to first understand the idea of element-wise operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1e126f0-7fe5-4774-9407-c52e588b6d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 7, 9])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([1, 2, 3]) + tensor([4, 5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad37440-98cb-4200-b2a2-5789ae65f2cf",
   "metadata": {},
   "source": [
    "This is element-wise operation.  \n",
    "These are rank-1 tensor of size 3. As they match,it takes the corresponding items and adds them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8caca63-2859-42c1-bfab-9c45b04776f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1010, 28, 28])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_3_tens - mean3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa206a-935c-4f82-a9a5-555caacb0a89",
   "metadata": {},
   "source": [
    "When we have different shapes as described before, what it ends up doing is copying mean3 1010 times and acts as if we had valid_3_tens minus 1010 copies of mean3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444183e-3ffe-4a6e-ad53-af125cc89a8f",
   "metadata": {},
   "source": [
    "Then we find the absolute value and call mean((-1, -2))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d0e40-b329-4c19-a851-b84671b084b8",
   "metadata": {},
   "source": [
    "We can now create is_3 function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3da7b41c-797f-465d-8240-409202cdaa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_3(x): return mnist_distance(x, mean3) < mnist_distance(x,mean7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97d864-3a76-48af-ae97-91bc34b0433f",
   "metadata": {},
   "source": [
    "The function figures out if the distance between the image in question (x) and mean3 is less than the distance between the image in question (x) and mean7. If it is, then its a 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12424f0-b865-4c98-9fc6-09c57d08cf73",
   "metadata": {},
   "source": [
    "Let's check with a_3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "983e5ad3-9a26-4e33-93ce-d0e8ef15eeb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(1.))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_3(a_3), is_3(a_3).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6de3a-0401-4ffe-a186-d6c952b58c0b",
   "metadata": {},
   "source": [
    "Checks whether the image is a 3 and turns it into a float.  \n",
    "If true, it becomes a 1. like in the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd390b92-3643-47c4-bc80-0bc1b24bc285",
   "metadata": {},
   "source": [
    "Using broadcating, we can check the whole validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc01b606-857c-4bdb-a067-739ee2d2b56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False,  True,  True])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_3(valid_3_tens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cec84d-d181-4221-98d7-7e57b565b2ee",
   "metadata": {},
   "source": [
    "Now, we can calculate the accuracy of the threes and sevens by taking the average of the function for all 3s and 7s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "206f0199-9790-41cb-89d0-4c4b87ad840e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9168), tensor(0.9854), tensor(0.9511))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_3s = is_3(valid_3_tens).float().mean()\n",
    "accuracy_7s = 1 - is_3(valid_7_tens).float().mean()\n",
    "accuracy_3s, accuracy_7s, (accuracy_3s + accuracy_7s)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d809c8-0814-4e4b-9099-884650e8f4c7",
   "metadata": {},
   "source": [
    "This performs is_3 on our whole valid_3_tens and then turns that into float and takes the mean. Same is done for 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460202ff-271f-417f-baca-c6eb590924d1",
   "metadata": {},
   "source": [
    "Accuracy is 91% for 3s, 98% for 7s and 95% for both.   \n",
    "This is a good baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c92bf0-eb84-45f1-ab20-dd5e8a6fb5f9",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d1ee9-36b1-4353-8fec-ea59857e909f",
   "metadata": {},
   "source": [
    "But in ML, according to Arthur Samuel, we don't have a function which has parameters that we are testing against some kind of measure of fitness and then using it to improve the parameters. We just did one step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016cbcb3-f7c1-4bb5-9dde-d370fb11e04e",
   "metadata": {},
   "source": [
    "Suppose, we arrange for some automatic means of testing the effectiveness of any current weight assignment in terms of the actual performance and provide a mechanism for altering the weight assignment so as to maximize the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dccc8bc-89d7-4335-81db-036516522c50",
   "metadata": {},
   "source": [
    "We need some way to get our model to become better and better as we keep iterating. \n",
    "Let's think of a function which has parameters. So instead of finding an ideal image and seeing how far away something is from the ideal image, what we could instead do is come up with a set of weights for each pixel.\n",
    "So in place that you expect to find 3, you could give those high weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843e280-00ef-48dd-b205-35c7383cb3c5",
   "metadata": {},
   "source": [
    "We can come up with a function where the probability of something being, for example an 8, is equal  to the pixel in the image(x) multiplied by some sort of weight(w) then we sum up.  \n",
    "\n",
    "def pr_eight(x,w): return (x*w).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594bad5-c3d0-4f5b-9032-baed01c07244",
   "metadata": {},
   "source": [
    "So anywhere in the image we are looking at with high weights, its going to end up with a high probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e9700-2972-4164-ac21-9ba035ad933f",
   "metadata": {},
   "source": [
    "x is the image represented as a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6127b91-426b-4f88-a13d-ebfe797b687b",
   "metadata": {},
   "source": [
    "So here are the steps that we are going to require, to turn this function into a machine learning classifier:  \n",
    "1) We will start with a vector w(A vector is a Rank 1 tensor) containing random weights/parameters.  \n",
    "2) Then, we will predict whether the number is a 3 or 7.  \n",
    "3) Based on the predictions, calculate how good the model is (its loss).  \n",
    "4) Key step -> Calculate the gradient, which measure for each weight, how  changing that weight would change the loss.  \n",
    "5) Step/Change all the weights based on that calculation.  \n",
    "6) Go back to step 2 and repeat the process.  \n",
    "7) ... repeat until you decide to stop the training process (for instance because the model is good enough).  \n",
    "\n",
    "These steps are called Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e220bf5-4e9b-4d84-a3d4-16dc74ed206a",
   "metadata": {},
   "source": [
    "Before going back to our image classifier, let's illustrate what they look like in a simple case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a9285-0ea1-410a-b8eb-cf562f97fbf1",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830b0e1-b1ab-41ed-8070-9d5d38796fd5",
   "metadata": {},
   "source": [
    "First, we define a simple function, the quadratic. Let's pretend this is our loss function and x is a weight parameter of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "537d80a8-1375-430f-85c9-785cc7705966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8974781-4331-434a-8672-a85697d81549",
   "metadata": {},
   "source": [
    "plotting the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5600777-64c4-41a8-b115-304375be0d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(f, 'x', 'x**2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c6fe9-b83c-466f-a140-b122fc921ba6",
   "metadata": {},
   "source": [
    "Next, we need to find the bottom value of the graph.  \n",
    "The steps we described above starts by picking some random value for a parameter and calculating the value of the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5fbd2a6-094b-4a7c-8fdb-d48c872fd23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(f, 'x', 'x**2')\n",
    "plt.scatter(-1.5, f(-1.5), color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c1b122-9bd2-43f0-ab2e-a4888080d386",
   "metadata": {},
   "source": [
    "We pick 1.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4a579-89fa-46b3-9d0f-4b7282356a9f",
   "metadata": {},
   "source": [
    "Now we need to know if we increase x a bit, will x**2(the loss in this case) get better(better means the lossis smaller)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c843438-fe37-44bb-9879-75bd01cb2527",
   "metadata": {},
   "source": [
    "To get to the bottom of the curve, we need to calculate the gradient.  \n",
    "First, we pick a tensor value which we want gradients at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b6ad929-7672-42fc-8a91-3fd9d48eccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = tensor(3.).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5115bca-6304-4c93-af1a-4f8f4d62a3b3",
   "metadata": {},
   "source": [
    "We will modify this tensor with a special method called requires_grad.  \n",
    "This method tells PyTorch that anytime I do a calculation with xt, it should do what calculation it does so that I can take the derivative later.  \n",
    "An underscore(_) at the end of a PyTorch method means that this is called an in-place operation. So it will modify the tensor(3) to tell PyTorch that we want to be calculating gradients on it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc58d34-b47a-4ce0-a5be-9fa904f50e10",
   "metadata": {},
   "source": [
    "Now, if we call f on it (Remember f is just squarring it), but the value is not just 9, but 9 accompanied by a grad function (knows that a power has been taken)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0335981f-95b9-46c1-9f46-05c1e7f1a888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = f(xt)\n",
    "yt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6a18c-1bbf-4020-b558-ca31ad5feea2",
   "metadata": {},
   "source": [
    "So now, we can call a special method called , backward(), which refers to back propagation. This means take the derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee63423b-c36f-4f7a-bb8c-bce435ca65e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b90f4f-cb1d-48a9-82dc-d0b55ad6cf95",
   "metadata": {},
   "source": [
    "Once it does that we can look inside xt and find its gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3ae99ef-d856-4e33-ab32-b4fe4e173690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afbc9fa-fc71-476f-8b58-53e015daf22c",
   "metadata": {},
   "source": [
    "Remember, the derivative of  x**2 is 2*x, and we have x=3, so the gradients should be 2*3=6.  \n",
    "The derivative means its a slope. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5fb5b5-f793-4edf-a175-79231bd524f1",
   "metadata": {},
   "source": [
    "Lets repeat the steps with a vector argument(Rank1 tensor).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "743f917f-6d8b-4333-bc2c-5b94ba3c0b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  4., 10.], requires_grad=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = tensor([3., 4., 10.]).requires_grad_()\n",
    "xt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2685ca7-6e62-40de-a138-52909a1d6671",
   "metadata": {},
   "source": [
    "Let's add sum to our function so that it can take a vector(Rank 1 tensor) and return a scalar(Rank 0 tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "263f9e35-da41-4ca3-9cc7-617265490904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(125., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x): return(x**2).sum()\n",
    "\n",
    "yt =f(xt)\n",
    "yt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1070cbd4-6978-4398-b2ce-a245479ee10d",
   "metadata": {},
   "source": [
    "Our gradients are 2*xt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c44e910-539b-427f-8296-b5810090b1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  8., 20.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.backward()\n",
    "xt.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04813312-ee99-4eb1-a0ed-a554682bc5ee",
   "metadata": {},
   "source": [
    "The gradient only tells us the slope of our function but not how far to adjust the parameters. It however gives us an idea.  \n",
    "If the slope is very large, then wehave more adjustments to do,  whereas if the slope is very small, that may suggest that we are close to the optimal value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a6452-a039-4554-a401-8027969a6149",
   "metadata": {},
   "source": [
    "Now, we can do the stepping/changing with a learning rate.\n",
    "Learning rate -> small number(mostly between 0.001 and 0.1) that we multiply with the gradient so as to change the parameters.  \n",
    "Once you have a learning rate, you can adjust the parameters with this simple function:\n",
    "w -= gradient(w) * lr  \n",
    "w is the weights and lr is the learning rate.  \n",
    "We subtract all our weights off the gradient multiplied by our learning rate.  \n",
    "This is the essence of gradient descent, known as stepping our parameters using an optimiser step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b49e505-093a-4221-9346-edd81cca5cbb",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0f6fae-a619-4799-9665-bce273dc131c",
   "metadata": {},
   "source": [
    "Let's use gradient descent to solve an actual problem.  \n",
    "Imagine you were measuring the speed of a roller coaster as it went over the top of a hump. It would start fast, and then get slower as it went up the hill; it would be slowest at the top, and it would then speed up again as it went downhill. You want to build a model of how the speed changes over time. If you were measuring the speed manually every second for 20 seconds, it might look something like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10f61277-5b8e-4bcf-9abc-8f9e45a76645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = torch.arange(0,20).float(); time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f1db3f4-0f10-45ce-8af0-a67e0dcdfbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe7ed8e63d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUh0lEQVR4nO3df4wcd3nH8fdTxyknoFxCrq5zSerQRka0EXE4RdBQlBIShxTFboSiUNS6EMlChYqorcEREqVVpZhahdIWUbmEYioKgeA4FgSM6wSh/kHggvM7GJsoLr449gEx4cepJObpHzuXnM+7d3u3O7sze++XtNr5td5H473Pzn7nO9+JzESSVD+/0u8CJEmLY4BLUk0Z4JJUUwa4JNWUAS5JNXVaL9/srLPOylWrVvXyLSWp9u69994fZObI7OU9DfBVq1YxPj7ey7eUpNqLiEPNltuEIkk1ZYBLUk0Z4JJUUwa4JNWUAS5JNdXTXiiLsXPfBFt37+eJ41OcPTzEprWrWb9mtN9lSVLfVTrAd+6b4KYdDzL1zAkAJo5PcdOOBwEMcUlLXqWbULbu3v9ceE+beuYEW3fv71NFklQdlQ7wJ45PLWi5JC0llQ7ws4eHFrRckpaSSgf4prWrGVq+7KRlQ8uXsWnt6j5VJEnVUemTmNMnKu2FIkmnqnSAQyPEDWxJOlWlm1AkSa0Z4JJUUwa4JNWUAS5JNTVvgEfE6oi4b8bj6Yi4MSLOjIg9EXGgeD6jFwVLkhrmDfDM3J+ZF2XmRcCrgJ8DtwObgb2ZeQGwt5iXJPXIQptQLge+l5mHgHXA9mL5dmB9F+uSJM1joQF+PfCZYnpFZh4ppp8EVjR7QURsjIjxiBifnJxcZJmSpNnaDvCIOB24Bvj87HWZmUA2e11mbsvMscwcGxkZWXShkqSTLeQI/I3AtzPzaDF/NCJWAhTPx7pdnCSptYUE+Ft4vvkEYBewoZjeANzRraIkSfNrK8Aj4oXAFcCOGYu3AFdExAHgDcW8JKlH2hrMKjN/Brx01rIf0uiVIklqoux7+lZ+NEJJqqNe3NPXS+klqQS9uKevAS5JJejFPX0NcEkqQS/u6WuAS1IJenFPX09iSlIJenFPXwNckkpS9j19bUKRpJoywCWppgxwSaopA1ySasoAl6SaMsAlqaYMcEmqKQNckmrKAJekmjLAJamm2r2l2nBE3BYR34mIRyPiNRFxZkTsiYgDxfMZZRcrSXpeu0fgHwG+kpkvB14JPApsBvZm5gXA3mK+cnbum+DSLXdx/uYvcemWu9i5b6LfJUlSV8wb4BHxEuB1wC0AmfmLzDwOrAO2F5ttB9aXU+LiTd/SaOL4FMnztzQyxCUNgnaOwM8HJoH/iIh9EfHx4i71KzLzSLHNk8CKZi+OiI0RMR4R45OTk92puk29uKWRJPVLOwF+GnAx8LHMXAP8jFnNJZmZQDZ7cWZuy8yxzBwbGRnptN4F6cUtjSSpX9oJ8MPA4cy8p5i/jUagH42IlQDF87FySly8XtzSSJL6Zd4Az8wnge9HxPR9gC4HHgF2ARuKZRuAO0qpsAO9uKWRJPVLu3fk+Qvg0xFxOvAY8DYa4f+5iLgBOARcV06Ji9eLWxpJGlw7901UOj+i0XzdG2NjYzk+Pt6z95OkxZruxTazI8TQ8mXcfO2FPQ/xiLg3M8dmL/dKTElqog692AxwSWqiDr3YDHBJaqIOvdgMcElqog692NrthSJJS0oderEZ4JLUwvo1o5UK7NlsQpGkmjLAJammDHBJqikDXJJqygCXpJoywCWppgxwSaopA1ySasoAl6SaMsAlqaYMcEmqqbbGQomIx4GfACeAZzNzLCLOBG4FVgGPA9dl5lPllClJmm0hR+B/kJkXzbitz2Zgb2ZeAOwt5iVJPdJJE8o6YHsxvR1Y33E1kqS2tRvgCXw1Iu6NiI3FshWZeaSYfhJY0eyFEbExIsYjYnxycrLDciVJ09odD/y1mTkREb8O7ImI78xcmZkZEU1vb5+Z24Bt0LgrfUfVSpKe09YReGZOFM/HgNuBS4CjEbESoHg+VlaRkqRTzRvgEfHCiHjx9DRwJfAQsAvYUGy2AbijrCIlSadqpwllBXB7RExv/1+Z+ZWI+BbwuYi4ATgEXFdemZKk2eYN8Mx8DHhlk+U/BC4voyhJ0vy8ElOSasoAl6Saarcb4ZK1c98EW3fv54njU5w9PMSmtatZv2a032VJkgE+l537Jrhpx4NMPXMCgInjU9y040EAQ1xS39mEMoetu/c/F97Tpp45wdbd+/tUkSQ9zwCfwxPHpxa0XJJ6yQCfw9nDQwtaLkm9ZIDPYdPa1QwtX3bSsqHly9i0dnWfKpKk53kScw7TJyrthSKpigzweaxfM2pgS6okm1AkqaYMcEmqKZtQJA2sQb+S2gCXNJCWwpXUNqFIGkhL4UpqA1zSQFoKV1Ib4JIG0lK4ktoAlzSQlsKV1G0HeEQsi4h9EfHFYv78iLgnIg5GxK0RcXp5ZUrSwqxfM8rN117I6PAQAYwOD3HztRcOzAlMWFgvlHcDjwK/Vsx/EPhwZn42Iv4NuAH4WJfrk6RFG/Qrqds6Ao+Ic4A/BD5ezAfweuC2YpPtwPoS6pMktdBuE8o/Ae8BflnMvxQ4npnPFvOHgaZfcxGxMSLGI2J8cnKyk1olSTPMG+AR8SbgWGbeu5g3yMxtmTmWmWMjIyOL+SckSU200wZ+KXBNRFwNvIBGG/hHgOGIOK04Cj8HmCivTEnSbPMegWfmTZl5TmauAq4H7srMtwJ3A28uNtsA3FFalZKkU3TSD/y9wF9GxEEabeK3dKckSVI7FjSYVWZ+DfhaMf0YcEn3S5IktcMrMSWppgxwSaopA1ySasoAl6SaMsAlqaYMcEmqKQNckmrKAJekmjLAJammDHBJqikDXJJqygCXpJpa0GBWktRLO/dNsHX3fp44PsXZw0NsWrt6oO9xuVAGuKRK2rlvgpt2PMjUMycAmDg+xU07HgQwxAs2oUiqpK279z8X3tOmnjnB1t37+1RR9RjgkirpieNTC1q+FBngkirp7OGhBS1fitq5K/0LIuKbEXF/RDwcEX9bLD8/Iu6JiIMRcWtEnF5+uZKWik1rVzO0fNlJy4aWL2PT2tV9qqh62jkC/z/g9Zn5SuAi4KqIeDXwQeDDmfnbwFPADaVVKWnJWb9mlJuvvZDR4SECGB0e4uZrL/QE5gzz9kLJzAR+WswuLx4JvB7442L5duADwMe6X6KkpWr9mlEDew5ttYFHxLKIuA84BuwBvgccz8xni00OA033ckRsjIjxiBifnJzsQsmSJGgzwDPzRGZeBJxD4070L2/3DTJzW2aOZebYyMjI4qqUJJ1iQb1QMvM4cDfwGmA4IqabYM4BJrpbmiRpLu30QhmJiOFiegi4AniURpC/udhsA3BHSTVKkppo51L6lcD2iFhGI/A/l5lfjIhHgM9GxN8D+4BbSqxTkjRLO71QHgDWNFn+GI32cElSHziYVckcTU1SWQzwEjmampY6D2DK5VgoJXI0NS1l0wcwE8enSJ4/gNm5zw5r3WKAl8jR1LSUeQBTPgO8RI6mpqXMA5jyGeAlcjQ1LWUewJTPAC+Ro6lpKfMApnz2QimZo6lpqZr+3NsLpTwGuKTSeABTLptQJKmmDHBJqikDXJJqygCXpJryJGbFOZaEpFYM8ApzMCxJc7EJpcIcS0LSXAzwCnMsCUlzaeeemOdGxN0R8UhEPBwR7y6WnxkReyLiQPF8RvnlLi2OJSFpLu0cgT8L/FVmvgJ4NfDOiHgFsBnYm5kXAHuLeXWRY0lImks798Q8Ahwppn8SEY8Co8A64LJis+3A14D3llLlEtWNsSTsxSINrsjM9jeOWAV8Hfhd4H8zc7hYHsBT0/OzXrMR2Ahw3nnnverQoUMdF632zO7FAo0jeEdElOolIu7NzLHZy9s+iRkRLwK+ANyYmU/PXJeNb4Gm3wSZuS0zxzJzbGRkZIFlqxP2YpEGW1sBHhHLaYT3pzNzR7H4aESsLNavBI6VU6IWy14s0mBrpxdKALcAj2bmh2as2gVsKKY3AHd0vzx1wl4s0mBr5wj8UuBPgNdHxH3F42pgC3BFRBwA3lDMq0LsxSINtnZ6ofwPEC1WX97dctRN3hFFGmyOhTLgvCOKNLi8lF6SasoAl6SasglFUkteyVttBrikphyPvvpsQpHUlFfyVp8BLqkpr+StPgNcUlNeyVt9BrikprySt/o8iSmpKa/krT4DXFJLXslbbQa45mQ/YKm6DHC1ZD9gqdo8iamW7AcsVZsBrpbsByxVm00oauns4SEmmoT1QvoB24YulccjcLXUaT/g6Tb0ieNTJM+3oe/cN1FCtdLS0849MT8REcci4qEZy86MiD0RcaB4PqPcMtUP69eMcvO1FzI6PEQAo8ND3HzthW0fQduG3n87901w6Za7OH/zl7h0y11+eQ6YdppQPgn8K/CpGcs2A3szc0tEbC7m39v98tRvnfQDtg29v+xFNPjmPQLPzK8DP5q1eB2wvZjeDqzvblkaBI6l0V/+Ahp8i20DX5GZR4rpJ4EVrTaMiI0RMR4R45OTk4t8O9WRY2n0l7+ABl/HJzEzM4GcY/22zBzLzLGRkZFO30410mkbujrjL6DBt9huhEcjYmVmHomIlcCxbhalweFYGv2zae3qk9rAwV9Ag2axR+C7gA3F9Abgju6UI6lb/AU0+OY9Ao+IzwCXAWdFxGHgb4AtwOci4gbgEHBdmUVKWhx/AQ22eQM8M9/SYtXlXa5FkrQAXokpSTVlgEtSTRngklRTBrgk1ZQBLkk15XjgUoU5nrrmYoBLFeVogpqPTShSRTmaoObjEbgqbSk3ITiaoOZjgKuyBqEJoZMvoG7ck1SDzSYUVVbdmxA6vSeo46lrPga4KqvuTQidfgE5mqDmYxOKKqvuTQjd+AJyNEHNxSNwVVbdmxC8I47KZoCrsurehFD3LyBVn00oqrQ6NyFM171Uu0GqfAa4VKI6fwGp+jpqQomIqyJif0QcjIjN3SpKkjS/RR+BR8Qy4KPAFcBh4FsRsSszH+lWcVK/LeUrQVV9nRyBXwIczMzHMvMXwGeBdd0pS+q/Ti/EkcrWSYCPAt+fMX+4WCZVxs59E1y65S7O3/wlLt1y14LCt+5XgmrwlX4SMyI2AhsBzjvvvLLfTnpOp2Op1P1KUA2+To7AJ4BzZ8yfUyw7SWZuy8yxzBwbGRnp4O2khen0CNoLcVR1nQT4t4ALIuL8iDgduB7Y1Z2ypM51egTthTiqukU3oWTmsxHxLmA3sAz4RGY+3LXKpA51OpaKF+Ko6jpqA8/MO4E7u1SL1FWb1q4+qQ0cFn4E7YU4qjKvxNTA8ghag84A10DzCFqDzNEIJammDHBJqikDXJJqygCXpJoywCWppiIze/dmEZPAoUW+/CzgB10sp9usrzPW1xnr60zV6/vNzDxlLJKeBngnImI8M8f6XUcr1tcZ6+uM9XWm6vW1YhOKJNWUAS5JNVWnAN/W7wLmYX2dsb7OWF9nql5fU7VpA5cknaxOR+CSpBkMcEmqqcoFeERcFRH7I+JgRGxusv5XI+LWYv09EbGqh7WdGxF3R8QjEfFwRLy7yTaXRcSPI+K+4vH+XtVXvP/jEfFg8d7jTdZHRPxzsf8eiIiLe1jb6hn75b6IeDoibpy1TU/3X0R8IiKORcRDM5adGRF7IuJA8XxGi9duKLY5EBEbeljf1oj4TvH/d3tEDLd47ZyfhRLr+0BETMz4P7y6xWvn/Fsvsb5bZ9T2eETc1+K1pe+/jmVmZR407uzzPeBlwOnA/cArZm3z58C/FdPXA7f2sL6VwMXF9IuB7zap7zLgi33ch48DZ82x/mrgy0AArwbu6eP/9ZM0LlDo2/4DXgdcDDw0Y9k/AJuL6c3AB5u87kzgseL5jGL6jB7VdyVwWjH9wWb1tfNZKLG+DwB/3cb//5x/62XVN2v9PwLv79f+6/RRtSPwS4CDmflYZv4C+CywbtY264DtxfRtwOUREb0oLjOPZOa3i+mfAI8CdRtseh3wqWz4BjAcESv7UMflwPcyc7FX5nZFZn4d+NGsxTM/Y9uB9U1euhbYk5k/ysyngD3AVb2oLzO/mpnPFrPfoHFD8b5osf/a0c7fesfmqq/IjeuAz3T7fXulagE+Cnx/xvxhTg3I57YpPsQ/Bl7ak+pmKJpu1gD3NFn9moi4PyK+HBG/09vKSOCrEXFvRGxssr6dfdwL19P6D6ef+w9gRWYeKaafBFY02aYq+/HtNH5RNTPfZ6FM7yqaeD7RogmqCvvv94GjmXmgxfp+7r+2VC3AayEiXgR8AbgxM5+etfrbNJoFXgn8C7Czx+W9NjMvBt4IvDMiXtfj959XRJwOXAN8vsnqfu+/k2Tjt3Ql+9pGxPuAZ4FPt9ikX5+FjwG/BVwEHKHRTFFFb2Huo+/K/y1VLcAngHNnzJ9TLGu6TUScBrwE+GFPqmu853Ia4f3pzNwxe31mPp2ZPy2m7wSWR8RZvaovMyeK52PA7TR+qs7Uzj4u2xuBb2fm0dkr+r3/Ckenm5WK52NNtunrfoyIPwPeBLy1+JI5RRufhVJk5tHMPJGZvwT+vcX79nv/nQZcC9zaapt+7b+FqFqAfwu4ICLOL47Srgd2zdpmFzB9xv/NwF2tPsDdVrSZ3QI8mpkfarHNb0y3yUfEJTT2cU++YCLihRHx4ulpGie7Hpq12S7gT4veKK8GfjyjuaBXWh759HP/zTDzM7YBuKPJNruBKyPijKKJ4MpiWeki4irgPcA1mfnzFtu081koq76Z51T+qMX7tvO3XqY3AN/JzMPNVvZz/y1Iv8+izn7Q6CXxXRpnqN9XLPs7Gh9WgBfQ+Ol9EPgm8LIe1vZaGj+nHwDuKx5XA+8A3lFs8y7gYRpn1b8B/F4P63tZ8b73FzVM77+Z9QXw0WL/PgiM9fj/94U0AvklM5b1bf/R+CI5AjxDox32BhrnVPYCB4D/Bs4sth0DPj7jtW8vPocHgbf1sL6DNNqPpz+D072yzgbunOuz0KP6/rP4bD1AI5RXzq6vmD/lb70X9RXLPzn9mZuxbc/3X6cPL6WXpJqqWhOKJKlNBrgk1ZQBLkk1ZYBLUk0Z4JJUUwa4JNWUAS5JNfX/OI3JPp2z2fkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "speed = torch.randn(20)*3 + 0.75*(time - 9.5)**2 + 1\n",
    "plt.scatter(time, speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cdc12a-1381-4b30-b2b4-4cdbe1c1fac6",
   "metadata": {},
   "source": [
    "We want to create a function that estimates at random time, what is the speed of the roller-coaster.  \n",
    "We start by guessing a function of the form a*(time**2) + (b * time) + c. This is a quadratic functions.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ce25c-1c12-4679-9b5a-8587df616714",
   "metadata": {},
   "source": [
    "So let's collect the parameters in one argument and thus separate the input,t, and the parameters, params.  \n",
    "The parameters are a, b, c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2be2f916-68d5-42c4-a003-c90ecdde3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(t, params):\n",
    "    a,b,c = params\n",
    "    return a*(t**2) + (b*t) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db187e1-92e1-4813-944b-d58127ac8637",
   "metadata": {},
   "source": [
    "In Python, you can split out a list or collection into its components like this:  \n",
    "a,b,c = params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa08009-f551-4061-999c-8c4e7357899b",
   "metadata": {},
   "source": [
    "We will need to find the best value for a,b,c.  \n",
    "We can find this choosing a loss function, which will return a value based on a prediction and a target.  \n",
    "For continous data, it is common to use mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20a11d8b-cbae-476b-9f46-c792b295f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(preds, targets): return((preds - targets)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858fdc7-393d-4b8f-b9be-d3db181c53a8",
   "metadata": {},
   "source": [
    "Looking at out 7 steps process:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2c954c-163f-45e6-9aa6-29ada1fcac80",
   "metadata": {},
   "source": [
    "1) Initialize the weights  \n",
    "We want to come up with a set of three parameters a, b, c.  \n",
    "So we initialize a, b, c to random values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e0653a9-3dd9-4af1-866d-45db8784a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.randn(3).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7978aa4-f130-467b-9c8b-d1516cb221fb",
   "metadata": {},
   "source": [
    "In PyTorch, we get random values using randn() and 3 to state that we want 3 of them.  \n",
    "Remember, we will be adjusting them so we tell PyTorch we want the gradients.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19adc65f-a007-440f-a877-ace7d7226bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "orig_params = params.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18da8535-255e-40fe-ad49-72d0d5077ab6",
   "metadata": {},
   "source": [
    "Save them this way so we can check them out later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3c14f-735d-4601-af9b-f98f676edcdc",
   "metadata": {},
   "source": [
    "2) Calculate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88d1664c-d08e-454f-8620-b09e9426d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = f(time, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c7f084-1045-467e-9c12-f31791f3a137",
   "metadata": {},
   "source": [
    "Let's create a function to see how close our predictions are to our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a139e776-1497-4629-9fad-c6312f899582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_preds(preds, ax=None):\n",
    "    if ax is None: ax=plt.subplots()[1]\n",
    "    ax.scatter(time, speed)\n",
    "    ax.scatter(time, to_np(preds), color='red')\n",
    "    ax.set_ylim(-300, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aee4bc36-edc1-4b6e-9823-3392b4a19c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd56a78-5c9f-4d0b-9044-bab122982a4b",
   "metadata": {},
   "source": [
    "Red is our prediction, Blue is our target.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57696bbe-1711-4a13-8e42-5eff8a1f1d57",
   "metadata": {},
   "source": [
    "This doesn't look very close."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f640f-8819-49f3-9caf-ffb030e1d37a",
   "metadata": {},
   "source": [
    "3) Calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "368d419c-3b37-4e41-9056-0a1d908db78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25823.8086, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse(preds, speed)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37cfb2-e036-454c-b075-dd9cb237df3c",
   "metadata": {},
   "source": [
    "We need to improve this as the loss is very big."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f226936-5334-459c-a6fe-bb7d070d2204",
   "metadata": {},
   "source": [
    "4) Calculate the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bbe65f3e-4df4-4afa-97fc-b87849639811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-53195.8633,  -3419.7148,   -253.8908])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "params.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac4de37-084b-4ecd-beb7-63bf661b8569",
   "metadata": {},
   "source": [
    "We first call backward() then get grad.  \n",
    "This says that each of our parameter has a gradient that is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bec015-e24f-434f-972e-7f0a8e4d4232",
   "metadata": {},
   "source": [
    "Let's pick a learning rate of 10^-5 or 1e-5 or 0.00001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7493ba36-dfab-41a0-a5e5-6c2f1374bf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5320, -0.0342, -0.0025])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params .grad * 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "da62dbcf-f6bb-4e1a-8be9-d52e8713c313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7658, -0.7506,  1.3525], requires_grad=True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974bd9d0-c276-43b1-ad1d-3415817849da",
   "metadata": {},
   "source": [
    "5) Step the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d82b0-488f-4610-a65f-1798dfe9f346",
   "metadata": {},
   "source": [
    "Remember, stepping the weights means minus equals the learning rate times the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e5f8909-64cb-4a0c-841b-ec5cee289492",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "params.data -= lr * params.grad.data\n",
    "params.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309c012-0794-45e9-800c-a685defce842",
   "metadata": {},
   "source": [
    ".data is a special attribute in PyTorch, which if you use it, then the gradient is not calculated.  \n",
    "We only want the gradient calculated of our function f. So when we step the weight, we have to use .data attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f090f5-185e-4d8d-9f52-75f19ed0e6cc",
   "metadata": {},
   "source": [
    "params.grad = None -> deletes the gradients that we already had"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045473a1-012a-4795-90f2-98d66ae05ad2",
   "metadata": {},
   "source": [
    "Let's see if the loss improved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76d146c9-951c-4606-8948-9756cd9d8c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5435.5356, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = f(time, params)\n",
    "mse(preds, speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4160d8ae-c97c-4f74-982b-b5248f94a2b5",
   "metadata": {},
   "source": [
    "plotting this:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7788027b-8630-4049-9ee1-690de5ce5c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df802e-33b9-423a-9f55-d0dac023a1f7",
   "metadata": {},
   "source": [
    "6) Repeat this process a few times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b6ff8d-eef5-4452-8cad-6a574073ee3e",
   "metadata": {},
   "source": [
    "We will create a function with the previous line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7107b84-09d9-426d-a831-90ae53018a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_step(params, prn = True):\n",
    "    preds = f(time, params)\n",
    "    loss = mse(preds, speed)\n",
    "    loss.backward()\n",
    "    params.data -= lr * params.grad.data\n",
    "    params.grad = None\n",
    "    if prn: print(loss.item())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102828ff-6eb7-4fee-943a-c319770c8ef7",
   "metadata": {},
   "source": [
    "Iterate 10 times:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "88fa42dc-fd6d-49ba-8004-303075c5a69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5435.53564453125\n",
      "1577.44921875\n",
      "847.3778076171875\n",
      "709.2225341796875\n",
      "683.0758056640625\n",
      "678.1243896484375\n",
      "677.1838989257812\n",
      "677.0023803710938\n",
      "676.9645385742188\n",
      "676.9537353515625\n"
     ]
    }
   ],
   "source": [
    "for i in range(10): apply_step(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976eca1-d968-4b47-8378-0405d038a285",
   "metadata": {},
   "source": [
    "We can see the loss decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4226fd88-7ec5-41f6-9049-10f7c4c9e55c",
   "metadata": {},
   "source": [
    "We can plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9419b13e-c612-497e-80dc-0fe6794cc3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axs = plt.subplots(1, 4, figsize = (12, 3))\n",
    "for ax in axs: show_preds(apply_step(params, False), ax)\n",
    "plt.tight_layout()\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9191a93c-32ad-48a2-9e63-d753c2a52ca2",
   "metadata": {},
   "source": [
    "7) Stop  \n",
    "We stop at 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8171d2fd-8c68-4408-90cd-376e082d04ce",
   "metadata": {},
   "source": [
    "## MNIST Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ff99b-842d-41ea-acad-6f62a44a7f33",
   "metadata": {},
   "source": [
    "We need to apply this 7 steps to the MNIST problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2c2032-3a3b-4076-b087-23f21f377ca7",
   "metadata": {},
   "source": [
    "We need a loss function that represents how good our model is.  \n",
    "From the loss function, we can calculate our gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5412a4a-d16f-4b64-95d9-c84dc9f4de9f",
   "metadata": {},
   "source": [
    "Gradient-> measure of how the loss function changes with small tweaks to the weights.  \n",
    "Gradient/slope = y_new - y_old/ x_new - x_old."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c58ab6-8dc6-42ca-8b1c-c2765895648e",
   "metadata": {},
   "source": [
    "We have x, the images. We'll concatenate them all into a single tensor and also change then from a list of matrices (Rank3 tensor) to a list of vectors (Rank2 tensor).  \n",
    "This can be achieved by view, a Pytorch method that changes the shape of a tensor without changing its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26a554d7-16e7-438a-af77-9ad569fd0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd3c40-244c-434c-b1be-b7b1a76b0e56",
   "metadata": {},
   "source": [
    "-1 is a special parameter to view thatmeans make the axis as big as necessary to fit all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fbd5a9-8979-469a-957d-0bce83aff61a",
   "metadata": {},
   "source": [
    "We want the number of columns to be equal to the numbet of pixels in the image 28*28.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec5e3d-0501-4e47-91f1-d402b59a2272",
   "metadata": {},
   "source": [
    "cat -> concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd9696-2998-49bb-b210-c86ad389fc50",
   "metadata": {},
   "source": [
    "Now we need labels.  \n",
    "Our labels will be 1 for each of the 3s and 0 for each of the 7s. This is basically a \"is_3\" model. This will create a vector and we need it to be matrix in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a30b23e-6feb-4970-81eb-06099505d4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70acadfa-75b5-481c-803b-e98198fe1a1c",
   "metadata": {},
   "source": [
    ".unsqueeze(1) will add an additional unit dimension to the position[1]. This will turn up from a vector of 12396 long to a matrix of 12396 rows and one column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f2917-5f4b-4bd8-a919-24050328b313",
   "metadata": {},
   "source": [
    "Now we turn our x and y into a Dataset.  \n",
    "Dataset -> something we can index into, using square brackets and when we do so, its expected to return a tuple of (x, y)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c007e8-ce5c-4519-8214-f49b1d5781ca",
   "metadata": {},
   "source": [
    "Python provides a zip function which when combined with list, provides a simple way to get this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2c7f5bcd-875d-4093-a4e7-8e39e1e3ac5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x, train_y))\n",
    "x, y = dset[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbff029-0116-4d0e-b64f-cf57a7e38d1c",
   "metadata": {},
   "source": [
    "We will turn our x and y into dataset and when we index into it, it will return a tuple containing our independent variables, x, and dependent variable, y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7775cec2-bc55-4bf3-8605-62e9e514329f",
   "metadata": {},
   "source": [
    "The list() gives us the dataset and when we index into it, it will give us one image,x, and one label,y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d0b77-c0fe-4116-9d2a-c9295391bfef",
   "metadata": {},
   "source": [
    "Our image is 784 long vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ada9e2-62ce-4303-a182-02ad933318a7",
   "metadata": {},
   "source": [
    "x,y = dset[0] is called destructuring the tuple, which means, we are taking the two parts of the tuple and putting the first part in one variable and secong part in other variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d1efa7-6855-4bca-89d6-c774aa25f529",
   "metadata": {},
   "source": [
    "Repeat the same step for the validation set:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e8409583-7fea-4a03-8a98-fb67eaf65f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7eb8a-969b-4ac7-9665-15f61fef88e4",
   "metadata": {},
   "source": [
    "Now we will start our 7 step process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cde334-df21-45e3-bfb6-78db5c683ec7",
   "metadata": {},
   "source": [
    "1) Initialize our parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0568904-a428-4f43-a6d5-f019f56911d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return(torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4b8779fe-31ef-4e57-9093-748e086c0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c7de8-14bb-4a02-b40e-de825338cbf1",
   "metadata": {},
   "source": [
    "We have a function given some size and shape if you like.  \n",
    "Then we randomly initialize using normal random number distribution(randn). randn has a variance of 1 (std=1.0).  \n",
    "Then we tell PyTorch we want gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e75c867-0d3d-4cb3-beed-7ee7c573cf03",
   "metadata": {},
   "source": [
    "Our weights will be 28*28 becauseevery pixel is going to need a weight and then 1 because we are going to need to have that unit access to make it a column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24833d2b-aea5-42e1-9291-09e28d8a79f9",
   "metadata": {},
   "source": [
    "NB: weight*pixels is not going to be enough because it will always be zero when pixels are equal to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7509182-0117-4393-996d-303494e1e838",
   "metadata": {},
   "source": [
    "Remember y= w*x + b  \n",
    "we still need b, bias, which is a single number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa42e3-25eb-4270-97cf-9a7cdf5b26e3",
   "metadata": {},
   "source": [
    "Initializing a random number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "310385c4-2724-4354-b33b-1be803eec67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc39ce0-149e-407b-90c8-b9ebb07e6f97",
   "metadata": {},
   "source": [
    "Weights and bias is what makes parameters.  \n",
    "Parameters is what changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8950f0-ab64-472e-a713-30ba54665491",
   "metadata": {},
   "source": [
    "2) Calculate the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fd8db6-d4f8-4f8e-aa9c-8819ce2c6860",
   "metadata": {},
   "source": [
    "For one image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "078379c0-a44c-41cb-bfa3-1a471aa9250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_454/4052062786.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2981.)\n",
      "  (train_x[0] * weights.T).sum() + bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([20.2336], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x[0] * weights.T).sum() + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea1decb-d39f-4d0f-933b-b013a7bf4fb8",
   "metadata": {},
   "source": [
    "Here, we take the 1 image and multiply by the wights only to transpose them to make them line up in terms of rowns and columns and add it up and then add the bias. This is the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8cb2f7-b75c-4eda-a4c6-9ea20e19a312",
   "metadata": {},
   "source": [
    "We want to do that for every image.  \n",
    "We could us a for loop but it will be every slow and Python loops don't run on GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33937b9-4a7b-4baf-b297-24b031fec3b9",
   "metadata": {},
   "source": [
    "For this reason, a matrix multiplication is the best as it calculates w*x for every row of a matrix.  \n",
    "In Python, matrix multiplication is represented by the @ operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8630cdcd-8849-4305-b83e-a163420de41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.2336, 17.0644, 15.2384,  ..., 18.3804, 23.8567, 28.6816], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear1(xb): return xb@weights + bias\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629d1c2-6c7e-4c85-9b9c-7215d059d9eb",
   "metadata": {},
   "source": [
    "First element is same as what we had calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7aa641-fe27-47da-8a61-292dc1a0504b",
   "metadata": {},
   "source": [
    "This equation, batch@weights + bias, is one of the two fundamental equations of any neural network (the other one is the activation function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730c6a4c-2099-49b5-95b0-6b77806739dc",
   "metadata": {},
   "source": [
    "3) Check our accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85319a-b10c-408e-9c98-0ce9883d1e18",
   "metadata": {},
   "source": [
    "We can decide that anything greater than 0 we will call it a 3, and anything less than a 0 we call it a 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e55908-483c-4a96-899d-e1cc401e1a58",
   "metadata": {},
   "source": [
    "So preds greater than 0.0 tells us whether or not something is predicted to be 3 or not. Then, we turn it to a float(1 or 0) because that's what our training set contains.  \n",
    "Then we check whether out thresholded predictions are equal to our training set.  \n",
    "This will return true when predicted correctly and false otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2bc144b6-2874-4e27-bd0e-9aa803a74084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = (preds>0.0).float() == train_y\n",
    "corrects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b808c31e-efca-4d1a-9f30-c46cca9305ad",
   "metadata": {},
   "source": [
    "So if we take the trues and falses and turn them into floats(1s and 0s) and find the mean, its 0.49(almost half with random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9420335a-7274-491c-b81c-23b37daec594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49464207887649536"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects.float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23882849-58d4-4973-8c32-106a0c82b9e8",
   "metadata": {},
   "source": [
    ".item() -> without it, the mean would be a tensor.  \n",
    "It is a rank 0 tensor, has no rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e37a399-4b98-4e83-b411-7c3cabf67d6c",
   "metadata": {},
   "source": [
    "This will help us calculate the derivative of our accuracy(by changing the parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea99bb-6cc1-465a-9e6a-4650b86443e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "4) Change the derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7a8152-b63a-4264-a2ad-ed4e321432ce",
   "metadata": {},
   "source": [
    "Let's change the weight by small bits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a34e71e-349e-4bac-9b28-e8bf6db85d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): weights[0] *= 1.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474c0df-c97a-4fea-a111-6515e0d358e9",
   "metadata": {},
   "source": [
    "This will make it a bit bigger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c25336-5ad1-49b8-b083-a3175b053898",
   "metadata": {},
   "source": [
    "with torch.no_grad() -> tells PyTorch not to calculate the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bea1253a-eb22-46da-a3b4-6449d4bc21a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49464207887649536"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(train_x)\n",
    "((preds>0.0).float() == train_y).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749b75f-d12a-4def-b57b-4e6cbef7fb41",
   "metadata": {},
   "source": [
    "Now we can calculate the predictions based on that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf647d5-7674-487d-8c01-9aac6cf3a654",
   "metadata": {},
   "source": [
    "As you can see, we get the same number.  \n",
    "Remember gradient = y_new - y_old/ x_new - x_old  \n",
    "y_new is what we have now and y_old is what we got(preds = 0.49), the subtraction is 0, and when we divide it by 1.0001(change, x) we get 0.  \n",
    "This means that the gradient is 0.\n",
    "This means our step/change is 0 and our prediction will be unchanges like we have seen.  \n",
    "The reason our gradient is 0 is because when we change a single pixel by a tiny bit, we might not even in any way change an actual prediction to change from a 3 predicting a 3 to a 7 or vice versa because we have the threshold ((preds>0.0).float() == train_y). This means our accuracy loss function here is very bumpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45d6e4b-b327-4d5c-bb8a-891db8c1f24f",
   "metadata": {},
   "source": [
    "Therefore, we need to use another thing other than accuracy as our loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6754ce3e-8a17-43a4-a519-609e2c10c191",
   "metadata": {},
   "source": [
    "Let's create a new function which will give us a lower loss when the accuracy is better, but it won't have a zero gradient.  \n",
    "It means a slightly better prediction needs to have a slightly better loss.  \n",
    "The purpose of this loss function is to measure the difference between the predicted values and true values(target)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f61613-c6f9-4ba2-9f1a-46e26676d5d3",
   "metadata": {},
   "source": [
    "Let's make another argument targets, a vector(Rank1) index over the images, with a value of 0 and 1, which tells whether the image is a 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22882ba0-18af-4ad0-8901-9fe5c4602868",
   "metadata": {},
   "source": [
    "Suppose we had three images which we knew were a 3, a 7, and a 3. And suppose our model predicted with high confidence (0.9) that the first was a 3, with slight confidence (0.4) that the second was a 7, and with fair confidence (0.2), but incorrectly, that the last was a 7. This would mean our loss function would receive these values as its inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a9e9fe97-27f2-4be0-a547-db00745bcd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "trgts  = tensor([1,0,1])\n",
    "prds   = tensor([0.9, 0.4, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd5bad-b4a5-4975-8c35-5488d1120ccb",
   "metadata": {},
   "source": [
    "Let's try find a loss function that measures the distance between predictions and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3f88c0e1-bbcf-465a-a309-823789c4883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82192ab9-f989-4735-96f1-25c358ee56cb",
   "metadata": {},
   "source": [
    "We're using a new function, torch.where(a,b,c). This is the same as running the list comprehension [b[i] if a[i] else c[i] for i in range(len(a))], except it works on tensors, at C/CUDA speed. In plain English, this function will measure how distant each prediction is from 1 if it should be 1, and how distant it is from 0 if it should be 0, and then it will take the mean of all those distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ecea77f4-b47d-4c74-a6aa-d5eda28fb688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.4000, 0.8000])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(trgts==1, 1-prds, prds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b56ec-a8e5-4369-a4e4-67e797eae652",
   "metadata": {},
   "source": [
    "torch.where(targets==1, 1-prds, prds) -> means where target=1, return 1-prediction, and where target is not 1, return predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53258ca5-c41d-49d3-a3ab-ef41732ac718",
   "metadata": {},
   "source": [
    "In the example, first will be 1-0.9=0.1 as the target is 1, next will be 0.4 as the target is 0 and the third will be 1-o.2=0.8 as the target is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcb4ce9-5a8c-4d6d-a632-7f8227d90631",
   "metadata": {},
   "source": [
    "As you can see, when the target is correct, the numbers are small(means that the loss is better)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721ee0d-76a2-4a98-a336-3d2dbdd78d59",
   "metadata": {},
   "source": [
    "Now we work on the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e8028a6a-d488-4a01-bf56-72d857d42f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4333)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(prds, trgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef37355-67bf-469e-a24f-9920e940f284",
   "metadata": {},
   "source": [
    "Let say we change our prediction for the one \"false\" target from 0.2 to 0.8 the loss will go down, indicating that this is a better prediction, the loss will get better to 0.23:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "879805ad-2eda-4c91-ac5e-565d86e65956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2333)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(tensor([0.9, 0.4, 0.8]),trgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54901e1-2a74-40b3-ba26-26a211f47e75",
   "metadata": {},
   "source": [
    "Problem: This will only work if predictions are between 0 and 1 so we need to ensure this is the case in the mnist problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5625941f-b226-425e-960a-524df2ef61bb",
   "metadata": {},
   "source": [
    "We need a function that can take the big numbers from our predictions and turn them to numbers between 0 and 1.  \n",
    "This can be achieved with a sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd01bf69-948e-45b1-b5ab-56daeb7e4f35",
   "metadata": {},
   "source": [
    "### Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b8396-dd19-4262-b09a-ae42bd720f1f",
   "metadata": {},
   "source": [
    "Sigmoid function works like this: if you pass a small number, e.g -4, you get a number close to 0, and if you pass a big number you get a number close to 1 but never past 1.\n",
    "In the middle, the curve looks like a y=x line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85507fa1-693d-454c-ae2d-7646ea293ff6",
   "metadata": {},
   "source": [
    "Sigmoid can be defined by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "26a6b90f-a105-4354-902d-59cdcfe6fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1/(1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225352c-1ff8-4482-9536-9863cb99d4ce",
   "metadata": {},
   "source": [
    "returns 1/1 + e to minus x.\n",
    "exp is just e to power something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "873374fd-7ba4-47ce-913a-c74686040f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece13101-d784-4c23-b7a2-421c1bcc8911",
   "metadata": {},
   "source": [
    "this shows the value of e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5221242d-a9f9-4eb1-98af-918b0901573a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.3890560989306495"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.e**2\n",
    "#squares the value of e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "12fa7e91-4c16-424c-ad9d-4d78d185793e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.3891)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(tensor(2.))\n",
    "#gives same result as above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83776767-4dac-4800-92b7-9e40cb3ce4b9",
   "metadata": {},
   "source": [
    "Let's update mnist_loss to apply sigmoid to its input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "263c97ba-0572-49db-9a5c-217e0b0a9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb95b48-3de4-418b-9a41-3cefe1ac6fc6",
   "metadata": {},
   "source": [
    "Now we have a metric(accuracy) and a loss.  \n",
    "Metric -> the thing we care about.  \n",
    "Loss -> the thing similar to what we care about but has a nicely behaved gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e6426-76ba-4fb5-bd50-3d595efc51b6",
   "metadata": {},
   "source": [
    "The key difference is that the metric is to drive human understanding and the loss is to drive automated learning. To drive automated learning, the loss must be a function that has a meaningful derivative. It can't have big flat sections and large jumps, but instead must be reasonably smooth. This is why we designed a loss function that would respond to small changes in confidence level. This requirement means that sometimes it does not really reflect exactly what we are trying to achieve, but is rather a compromise between our real goal and a function that can be optimized using its gradient. The loss function is calculated for each item in our dataset, and then at the end of an epoch the loss values are all averaged and the overall mean is reported for the epoch.\n",
    "\n",
    "Metrics, on the other hand, are the numbers that we really care about. These are the values that are printed at the end of each epoch that tell us how our model is really doing. It is important that we learn to focus on these metrics, rather than the loss, when judging the performance of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb3b43-5469-4a4e-be2d-6ecf122d3e8d",
   "metadata": {},
   "source": [
    "### SDG and mini batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea54fe7-ee4f-49d7-bc56-4acaaf534b7d",
   "metadata": {},
   "source": [
    "We need to use this to update the batches. We can do this by:  \n",
    "- Looping through every image  \n",
    "- calculate a prediction for that image  \n",
    "- calculate a loss then  \n",
    "- step the parameters  \n",
    "- do that for other images  \n",
    "This is very slow because we are doing a single step for a single image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41acb649-d4bb-4dee-baf6-f5606594a66a",
   "metadata": {},
   "source": [
    "We can go faster by doing a big matrix multiplication on GPU, then we can do a step based on the gradien looking at the entire dataset. But this is a lot of work updating the weights for many images.  \n",
    "So we can go a few data itema at a timme to calculate our loss and our step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5109338-bcd8-46f3-970c-a50a9362c2d0",
   "metadata": {},
   "source": [
    "The few data items are called minibatch.  \n",
    "The number of items in a minibatch is the batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939df35a-f596-4478-b012-5985dbb9fdb3",
   "metadata": {},
   "source": [
    "The larger the batch size means more accurate and stable estimates of your dataset's gradient on the loss function, but it will take longer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc251a-94db-4cb1-a619-df930673da6f",
   "metadata": {},
   "source": [
    "We will use a DataLoader to shuffle and minibatch collation. A DataLoader can take any Python collection and turn it into an iterator over mini-batches, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a7fdd6dc-4dbe-4099-8dc7-abdcc908cfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 3, 12,  8, 10,  2]),\n",
       " tensor([ 9,  4,  7, 14,  5]),\n",
       " tensor([ 1, 13,  0,  6, 11])]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll = range(15)\n",
    "dl = DataLoader(coll, batch_size=5, shuffle=True)\n",
    "list(dl)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a983dedc-59c6-496b-b423-77eca0a7f2de",
   "metadata": {},
   "source": [
    "coll = range(15) -> creates a collection that contains all numbers from 1 to 14  \n",
    "dl = DataLoader(coll, batch_size=5, shuffle=True) -> passes coll to DataLoader with a batch size of 5.    \n",
    "\n",
    "DataLoader can take any Python collection and turn it into an iterator over many batches. We see it in list(dl).  \n",
    "shuffle = True -> causes randomization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b741db2-72b7-4b6a-ad2c-f80d9e3d07c4",
   "metadata": {},
   "source": [
    "Remember, datasets return tuples and in the previous code we just have ints. So let's create tuples.  \n",
    "If we enumerate all letters of English, then we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0e9aac50-0564-4da0-92bb-e4053c1253eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = L(enumerate(string.ascii_lowercase))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23edf8b5-6db4-43b1-ad3a-3817ae434657",
   "metadata": {},
   "source": [
    "So if we pass this to our DataLoader with a batch size of 6, it returns tuples containing 6 of the first things and the associate 6 of the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ce43e77c-bc41-4d76-8b58-5bf340b2da46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([17, 18, 10, 22,  8, 14]), ('r', 's', 'k', 'w', 'i', 'o')),\n",
       " (tensor([20, 15,  9, 13, 21, 12]), ('u', 'p', 'j', 'n', 'v', 'm')),\n",
       " (tensor([ 7, 25,  6,  5, 11, 23]), ('h', 'z', 'g', 'f', 'l', 'x')),\n",
       " (tensor([ 1,  3,  0, 24, 19, 16]), ('b', 'd', 'a', 'y', 't', 'q')),\n",
       " (tensor([2, 4]), ('c', 'e'))]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, batch_size=6, shuffle=True)\n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d322f4-1075-43e9-b69f-d84fdc38f832",
   "metadata": {},
   "source": [
    "[17, 18, 10, 22,  8, 14] is like our independent variable, ([17, 18, 10, 22,  8, 14]) is like our dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6a476-ed5e-4f74-b6f8-ac7525c90551",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb696cb9-4f5d-4439-9163-3ce5e4c11d4f",
   "metadata": {},
   "source": [
    "It's time to implement the process we saw in <>. In code, our process will be implemented something like this for each epoch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64438026-afbf-468c-8030-f4d2565e54a6",
   "metadata": {},
   "source": [
    "for x, y in dl:  \n",
    "    pred = model(x)  \n",
    "    loss = loss_func(pred, y)  \n",
    "    loss.backward()  \n",
    "    parameters -= parameters.grad*lr  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf18973e-7d72-4405-879b-73d072329fcc",
   "metadata": {},
   "source": [
    "for x, y in dl: -> means for in dataloader return tuple  \n",
    "\n",
    "x, y destructures dataloader into first and second bit (x, y) then calculates predictions. From predictions and targets, we can calculate our loss. The .backward() will then calculate our gradients. Then we update the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c0db7-d96f-4792-97bc-b96dffd1de86",
   "metadata": {},
   "source": [
    "First, we initialize our parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "074e89c8-8e4b-4e90-9f24-985d2cc9b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28, 1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425538cb-fd87-424c-8a44-6f6ac5dcca83",
   "metadata": {},
   "source": [
    "A DataLoader can be created from a Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5385329c-711c-49e3-8be2-e87a3269bce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb, yb = first(dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74d023-13e3-4f3f-89aa-32a4ff7245b1",
   "metadata": {},
   "source": [
    "first() -> fastai function that grabs the first thing from an iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7214328-b3c9-4b83-87e7-ec6288cbc315",
   "metadata": {},
   "source": [
    "Then we display the shape of the first item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff95d8e3-dfc0-440c-b140-b274e6d71937",
   "metadata": {},
   "source": [
    "xb -> is 256 rows of the 784 long(28*28)  \n",
    "yb -> 256 labels that are 1(Remember the 0 label for 7s and 1 label for 3s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c09077-4c50-484a-aabc-ec9791f17be3",
   "metadata": {},
   "source": [
    "We'll do the same for the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b6eb3258-58b7-4180-8407-bf571a820671",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f4a413-a4c9-466b-8fd1-a172e1a6d003",
   "metadata": {},
   "source": [
    "Let's create a mini-batch of size 4 for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "592defe8-ebd9-47e6-adf8-cf18313598b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = train_x[:4]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c13b5-137c-4475-9b24-446ec32e4a36",
   "metadata": {},
   "source": [
    "This manually grabs the first 4 things for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3c73c8-290d-4296-8999-b07835dfdbe5",
   "metadata": {},
   "source": [
    "We pass the batch into a linear function that we created earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "110eb755-c3ff-4822-a82a-db0dedac0283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1876],\n",
       "        [-8.3973],\n",
       "        [ 2.5000],\n",
       "        [-4.9473]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=linear1(batch)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e48966f-7a80-4d84-a40d-b58fb9abfc91",
   "metadata": {},
   "source": [
    "This will give the prediction of these 4 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1cdfb-79de-4751-a9c2-7a6f9e997197",
   "metadata": {},
   "source": [
    "We can calculate the loss using the loss function we just used and let's grab the first 4 items of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1e8e88ef-e014-451b-81da-6c828bb02a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7419, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mnist_loss(preds, train_y[:4])\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce23c2-fd45-41ba-afb0-d04525f96ae8",
   "metadata": {},
   "source": [
    "Now we can calculate the gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "31bf647e-101c-48d1-a8de-837bdbaf8afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), tensor(-0.0061), tensor([-0.0420]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "weights.grad.shape, weights.grad.mean(), bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036052d7-40da-4217-8056-5734bdf4c283",
   "metadata": {},
   "source": [
    "torch.Size([784, 1] -> 784*1 is a column where the weights as a grad. It's what the change in loss for a small change in parameter.  \n",
    "bias.grad (-0.0008) is a sinle number because its a single number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067ba20-f61b-47e6-ad75-7db079f12b70",
   "metadata": {},
   "source": [
    "Put these step in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "729dddf6-0567-411a-b936-00313e045aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):     #pass the x batch, y batch and model  \n",
    "    preds = model(xb)             #calculate predictions  \n",
    "    loss = mnist_loss(preds, yb)  #calculate loss  \n",
    "    loss.backward()               #do backward step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff04785f-9380-4afe-a5ab-4a972ac50538",
   "metadata": {},
   "source": [
    "Test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bd098cc7-039b-4241-9a13-8131074c10a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0121), tensor([-0.0840]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)   #calculate gradient  \n",
    "weights.grad.mean(), bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9e61b-1f8c-4086-872a-7a204557775a",
   "metadata": {},
   "source": [
    "weights.grad.mean() -> mean of weights  \n",
    "bias.grad -> bias gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d49778-e780-4422-ab66-27c989bd6a80",
   "metadata": {},
   "source": [
    "Call it a second time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0300f573-21c8-4c2e-8e4e-78c2732069ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0182), tensor([-0.1260]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1) \n",
    "weights.grad.mean(), bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b1b806-f50b-43f1-86b0-590aec622b71",
   "metadata": {},
   "source": [
    "Here, we get a different value because loss.backward() calculates the gradient and adds them to the existing gradients (In the .grad attribute).  \n",
    "What we need to do is call grad.zero_().  \n",
    ".zero returns a tensor containing zeros and _ updates the weights.grad which is a tensor containing zeros.  \n",
    "If we do that and call it again, we get the same number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aff4a70b-1edf-473e-b23a-c8f597f62fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.grad.zero_()\n",
    "bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d471aa5b-d931-4525-b24a-f8698aab68bb",
   "metadata": {},
   "source": [
    "Now we train one epoch with SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0ef53a26-cf8d-482c-9421-469251c291e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e13abb-9291-433d-ae13-d22998deac97",
   "metadata": {},
   "source": [
    "First, we loop through the DataLoader, grabbing the x batch and the y batch to calculate the gradient.  \n",
    "Then we go through each of the parameter(the 784 weights and 1 bias) and for each of those update the parameters to go minus equal gradient times the learning rate.  \n",
    "This is our Gradient Descent Step.  \n",
    "Then we zero it out for the next time around the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d88dab5-fb1a-409c-9bab-a9ed2df2860d",
   "metadata": {},
   "source": [
    ".data -> special attribute in PyTorch that tells it not to upgate the gradients using that calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83740c48-a02b-4afd-ada6-22050301c421",
   "metadata": {},
   "source": [
    "This is the most basic Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b84bd45-9826-4147-85c4-8bee6f978e13",
   "metadata": {},
   "source": [
    "##### Difference between Stochastic Gradient Descent(SGD) and Gradient Descent(GD).  \n",
    "GD doesn't have this(for xb, yb in dl:) that loops through each mini batch. GD does it for the whole dataset each time around. So it updates parameters based on the whole dataset (We don't do this in practice, we use minibatches of different sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf0d87-807d-4d2c-b791-d28e2e4641e6",
   "metadata": {},
   "source": [
    "We also want to check how we're doing, by looking at the accuracy of the validation set. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0. So our accuracy for each item can be calculated (using broadcasting, so no loops!) with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "94ca1437-d0b9-4854-a0db-36abe618e801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds>0.0).float() == train_y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a67c7-0061-4b60-b89b-bf6113976908",
   "metadata": {},
   "source": [
    "That gives us this function to calculate our validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2b5253bd-f090-4f81-8a6b-1f0fd3e0d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds > 0.5) ==yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01c84f-6cc6-48d2-be59-8ea27dc1456a",
   "metadata": {},
   "source": [
    "We previously checked whether the prediction is less than 0, but since we are doing the sigmoid, sigmoid will squish everything between 0 and 1. So now we should compare the predictions to whether they are grater than 0.5 or not.  \n",
    "On the sigmoid plot we have, what used to be 0 is now 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548bb25-b06e-4e23-b3a9-88ac79e777b9",
   "metadata": {},
   "source": [
    "So to calculate the accuracy of the x batch and the y batch, we take the sigmoid of the predictions(xb.sigmoid()) then we compare to 0.5 to tell whether its a 3 or not.  \n",
    "We check what the actual target(yb) was, to se which ones are correct then we take the mean of those after converting the boolean to float."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82302b00-4fc7-40c7-8e47-0e9c184890b6",
   "metadata": {},
   "source": [
    "We can check if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "818e1bc1-3ccd-4a9d-a190-5fd549e8fa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch), train_y[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3299a1e9-1b48-4154-81f3-5938e67dbe81",
   "metadata": {},
   "source": [
    "To check the accuracy, we take the batch put it through our simple linear model, compare it to the 4 items of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56fc3e5-fad0-4b3e-91fd-3da6ac9b8a3b",
   "metadata": {},
   "source": [
    "and then put the batches together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "61c149ae-1128-49be-b56f-bd8e19de42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c691856-e53f-4fcb-8379-c43116447f38",
   "metadata": {},
   "source": [
    "If we do that for every batch in the validation set then we can loop through with a list comprehension (every batch in the validation set), get the accuracy based on some model(2nd line of code)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c72b2-8969-4e82-9002-8eaed49a6e0e",
   "metadata": {},
   "source": [
    "3rd line of code -> Stack those all up together to turn the list into a tensor, take the mean and convert to a standard Python scalar with .item and round it off to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b3f032-00a5-4435-ad27-41156ab06983",
   "metadata": {},
   "source": [
    "Here's the validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "23f9cd2e-6949-41b2-807d-a81d66c665cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5261"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f444fc7-e657-417b-9862-2d9dc81a1b1e",
   "metadata": {},
   "source": [
    "It's about 50% because its random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1681e6-2b97-4be9-8037-bcb9a83cc8db",
   "metadata": {},
   "source": [
    "So now we train for one epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "af8bfc9f-12a5-46ef-9bd1-7c16021d7bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6663"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1.\n",
    "params = weights, bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb3dc8-0557-4a7f-9254-61a5e0c2c02b",
   "metadata": {},
   "source": [
    "Our accuracy is now 68%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2d174-a347-4f71-a2de-2795763af2e5",
   "metadata": {},
   "source": [
    "Now, we repeat it a few times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "56e178f1-5006-4db9-b079-0a22c9739a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8265 0.89 0.9183 0.9275 0.9398 0.9466 0.9505 0.9525 0.9559 0.9579 0.9598 0.9608 0.9613 0.9618 0.9633 0.9637 0.9647 0.9657 0.9672 0.9677 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch(linear1,lr,params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50767d6-7596-4d65-bba9-fb2a462781b5",
   "metadata": {},
   "source": [
    "Accuracy goes up to about 97%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d073203-5f2c-4baf-827c-94b3254c4695",
   "metadata": {},
   "source": [
    "We've built an SGD of a simple linear function that is getting about 97% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472acae0-f1c0-4e6e-a733-878bfc98e994",
   "metadata": {},
   "source": [
    "We can simplify some steps through simple refactoring.  \n",
    "In the next step, we will create an object that will handle the SGD for us, called an optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d5167-daf1-426a-934a-5faaf941ba03",
   "metadata": {},
   "source": [
    "## Creating an Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ef10e-05ac-468a-a640-ec141ced9cd7",
   "metadata": {},
   "source": [
    "1) We'll get rid of the linear1 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "67d0bd52-3b10-4f5d-9913-f2bf70d55ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_454/3366534937.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear1??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6fb254-1ad9-4069-9eb6-c1ce210644a2",
   "metadata": {},
   "source": [
    "Remember it does x @ w + b.  \n",
    "There's a class in Python that does that called nn.linear module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2287f2-e2ec-4953-bfd1-b902a4c4f94e",
   "metadata": {},
   "source": [
    "Module -> object of a class that inherits from PyTorch class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a815c911-850d-41ec-9a48-89364aa51e00",
   "metadata": {},
   "source": [
    "nn.linear does two things:  \n",
    "    - does the linear1 function(x @ w + b) for us.  \n",
    "    - also initializes the parameters for us so we don't have to do (weights = init_params()) and (bias = init_params())  \n",
    "    \n",
    "We just create a nn.linear class and that's going to create a matrix of size(28, 28, 1) and bias of size 1. It will set requires_grad = True for us.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "10ae063a-3579-4e9b-b981-e89364317e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(28 * 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293284f-7d00-48a9-b757-802ba6889bad",
   "metadata": {},
   "source": [
    "When we call the fn, its going to do x @ w + b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4125eb-9e4a-4d56-afba-8b0c9081b543",
   "metadata": {},
   "source": [
    "To see the parameters, we would expect it to contain 784 weights and 1 bias, we can just call .parameters():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "22ae6efb-a3f4-4ab2-be87-13825702751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = linear_model.parameters()\n",
    "w.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab453496-84ed-4c52-bd41-ca77406af84c",
   "metadata": {},
   "source": [
    "We can destructure it to w and b.  \n",
    "Weights is (1, 784), bias is (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ca075-d0d4-4aad-afd7-9dd914977888",
   "metadata": {},
   "source": [
    "Now, we can create an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3e62e796-cd1b-4d05-a595-bd74e7d9589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self, params, lr): self.params, self.lr = list(params), lr\n",
    "    \n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -=p.grad.data * self.lr\n",
    "        \n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82265fab-d218-4b56-b5a0-dcd40ac9bc2b",
   "metadata": {},
   "source": [
    "init function -> passes the parameter to optimize and learning rate, and stores them away  \n",
    "step function -> goes through each parameter and does p.data -=p.grad.data * self.lr  \n",
    "zero_grad function -> goes through each parameter and zeros it out or sets it to None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24312cf5-3293-4811-8d04-f94c8c6c56be",
   "metadata": {},
   "source": [
    "This is our Basic Optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec06eb7-1319-47a4-9ab2-92d6c6b38db1",
   "metadata": {},
   "source": [
    "Now we can create an optimizer passing in the parameters of the linear model and our learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5bee4efe-19aa-4715-ac8f-1bafc195288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim(linear_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2722ee6c-6eb8-45a4-91b6-9188476d5dd0",
   "metadata": {},
   "source": [
    "Now our training loop looks through each of the minibatch in the data loader, calculates the gradient, does the opt.step and opt.zero_grad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0a815b01-e4c1-4ac2-bdfd-d03335f84b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ff34d-674d-4de3-bcf7-0be95998f056",
   "metadata": {},
   "source": [
    "Validation function doesn't need to change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "04e05eee-21c0-4d11-80cd-acccfd65c685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4608"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9d3fc-a35b-4ac0-830e-db0e52366c14",
   "metadata": {},
   "source": [
    "So let's put our training loop into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9d889bf5-ce96-4cf8-808c-db3adcb1eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20693ee-e615-41f6-b71c-765d6dff1c41",
   "metadata": {},
   "source": [
    "It will loop through a bunch of epochs called train_epoch and print validate_epoch and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "55d1fd44-14eb-47e8-bba8-86d6fd62552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.7685 0.8554 0.9135 0.9345 0.9482 0.957 0.9633 0.9657 0.9677 0.9696 0.9716 0.9736 0.9745 0.976 0.977 0.9775 0.9775 0.978 0.9785 "
     ]
    }
   ],
   "source": [
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b50cc-8631-4285-bbf5-d8846c6c0187",
   "metadata": {},
   "source": [
    "Results are different, but idea is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b48fcc3-0502-49ab-b430-96a0f0a9b14c",
   "metadata": {},
   "source": [
    "We don't need to comre up with BasicOptim, fastai provides SGD class which does the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b3fd2a8d-3208-4971-a4f6-53aa5dba8ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.8178 0.8496 0.914 0.9345 0.9482 0.957 0.9618 0.9657 0.9672 0.9692 0.9711 0.9741 0.975 0.976 0.9775 0.9775 0.978 0.9785 0.9789 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28, 1)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3b757-e545-4f88-935a-3221050d23fb",
   "metadata": {},
   "source": [
    "You can pass to SGD your parameters and learning rate like BasicOptim.  \n",
    "We get the same result as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c06c815-2bdc-4bb0-9ebd-dbbc7f6dc510",
   "metadata": {},
   "source": [
    "###### Fastai classes  \n",
    "- DataLoader -> stores the .train and .valid data.   \n",
    "\n",
    "- Learner -> we pass in our dataloders, model, optimization function, loss function and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bc66d95d-97aa-425a-8fbf-3c4227427780",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b1ba165b-9953-4eab-b568-72abf0581751",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28, 1), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537140e6-ac45-424f-8742-aa0be998e035",
   "metadata": {},
   "source": [
    "It will call train_model and train_epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b7cb8-75ae-408a-93a2-1fd7d78fc8c5",
   "metadata": {},
   "source": [
    "Now we can call fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fe770b57-5a87-483d-bc6a-ff2b8979b6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636709</td>\n",
       "      <td>0.503144</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.429828</td>\n",
       "      <td>0.248517</td>\n",
       "      <td>0.777233</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.161680</td>\n",
       "      <td>0.155361</td>\n",
       "      <td>0.861629</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.072948</td>\n",
       "      <td>0.097722</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.073205</td>\n",
       "      <td>0.936212</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027210</td>\n",
       "      <td>0.059466</td>\n",
       "      <td>0.950442</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.050799</td>\n",
       "      <td>0.957802</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>0.044980</td>\n",
       "      <td>0.964181</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>0.040853</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017330</td>\n",
       "      <td>0.037788</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eccf80a-85b9-4903-8edc-8d3c04bfb154",
   "metadata": {},
   "source": [
    "## Adding Non-Linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f317c-209d-4815-be30-7c1ecdd54269",
   "metadata": {},
   "source": [
    "This was just a linear function, we wanta neural network. Remember x@w + b is a linear function.   \n",
    "\n",
    "To turn it into a neural network, we have two linear functions exactly the sma ebut with different weights and biases and in between have, res = res.max(tensor(0.0)), which takes the result of our first linear function, res = xb@w1 + b1, and then does a max() between that and 0. So a max() of res and 0 is going to take any negative numbers and turn them into 0s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15bb18-e208-4e4e-8a4b-edd9774d0b23",
   "metadata": {},
   "source": [
    "A simple net does the following:  \n",
    "    - Takes a linear function  \n",
    "    - Replaces negatives with 0s  \n",
    "    -Takes that and puts it through another linear function  \n",
    "    \n",
    "This is a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9dba9c67-dd79-44a6-86ff-0bd14aba7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_net(xb):\n",
    "    res = xb@w1 + b1\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = xb@w2 + b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c3fc1-5ec2-41c3-9153-47f2f37e8a74",
   "metadata": {},
   "source": [
    "w1 and w2 -> weight tensors  \n",
    "b1 and b2 -> bias tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122c8995-2338-4d24-a854-6c92da9df509",
   "metadata": {},
   "source": [
    "Initializing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cd5a231e-aa3b-45e3-8636-d6d554977f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = init_params((28*28), 30)\n",
    "b1 = init_params(30)\n",
    "w2 = init_params((30,1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c303b0-95f8-4f31-bed2-b5b5a90a8893",
   "metadata": {},
   "source": [
    "The key point about this is that w1 has 30 output activations (which means that w2 must have 30 input activations, so they match). That means that the first layer can construct 30 different features, each representing some different mix of pixels. You can change that 30 to anything you like, to make the model more or less complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca57445a-0ef5-4c37-bf8b-7fe8f6619673",
   "metadata": {},
   "source": [
    "res = res.max(tensor(0.0)) is called the Rectified Linear Unit(ReLU).  \n",
    "In PyTorch, it has a function called F.relu. We can plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "734fb496-4046-4d5b-a192-a4d1fa847272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(F.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21257c2b-37f3-4632-9c30-849fa5cf3e9e",
   "metadata": {},
   "source": [
    "As you can see it is 0 for the negative values, and y=x for the positive values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f341d19b-c51d-4610-9c72-e6cb5a2977d2",
   "metadata": {},
   "source": [
    "Why do we do Linear layer ReLU:  \n",
    "If we get rid of the res = res.max(tensor(0.0)) line, which is the ReLu and just do linear layer then linear layer, we just make a linear model. No matter how many linear layer we stack on each other, it still is a linear layer.  \n",
    "But if you put a non-linearity module between them, its actually the opposite. This is called Universal Approximation Theorem, which is, if the size of the weights and bias matrices are big enough, it can actually approximate any arbitrary function (including our function of how to recognize 3s and 7s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fed0e4-f88f-4f23-bdd0-da4014666a5f",
   "metadata": {},
   "source": [
    "The three lines of code that we have here are known as layers. The first and third are known as linear layers, and the second line of code is known variously as a nonlinearity, or activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8118944f-3fdb-4ae5-a368-d0d9be785b70",
   "metadata": {},
   "source": [
    "The simple_net function is our universal approximation function as long as w1, b1, w2, b2 have the right numbers.  \n",
    "We know how to make them the right numbers using SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987596aa-9a78-4554-b7c2-a7022240baf0",
   "metadata": {},
   "source": [
    "Simplifying things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5fffb9a2-47c1-4108-af10-4b70b4c964d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53420f96-11f1-4be7-bd47-bf931f488216",
   "metadata": {},
   "source": [
    "nn.Sequential -> creates a module which will call each of the listed layers or functions in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce8a509-5827-4cc4-8a53-e78af901e7fe",
   "metadata": {},
   "source": [
    "In the simple_net function, we are taking the results of one and passing it to the next, then take the results of the next and pass it to the next and returned at the end. This is called Function Composition.  \n",
    "Composition -. when you take the results of one function and pass it to a new one, take the result and pass it to a new one etc.  \n",
    "Neural network is just doing function composition of linear functions and these are called Activation Functions or non-linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931bc5e7-def1-4558-9429-a7fb51d9dcb3",
   "metadata": {},
   "source": [
    "PyTorch provides nn.Sequential to do activation function for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3923b1f7-7321-435d-9739-0e6ae112b75a",
   "metadata": {},
   "source": [
    "NOTE: We are not using F.ReLU(function) but nn.ReLU(module)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1803f1-156a-4c21-812f-0e03d59b8571",
   "metadata": {},
   "source": [
    "Leaky ReLU -> not to make the ReLU function flat at the values less than 0 as 0 means the neurons are dead/do nothing. It rather makes a less steep line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d9ed67-83f0-4dc4-bb49-68657f4f1176",
   "metadata": {},
   "source": [
    "Now that we have a neural net, we can use the same learner we had but this time we pass simple_net instead of nn.linear that we use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca06fe6-f7ec-494c-bbce-cb8232ca68f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func = SGD, loss_func = mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b5b220-7c1f-449c-a24c-f07111725b03",
   "metadata": {},
   "source": [
    "Now we call fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a1289-6557-4d13-ba36-46d236584800",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a2990-b1e8-43e3-9405-5e48f0398ea8",
   "metadata": {},
   "source": [
    "Here,we only have two layers.  \n",
    "We have dropped ur learning rate from 1 to 0.1 because the deeper models(with more layers) all tend to be bumpier, less nicely behaved so often you need to use lower learning rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7984109-8b17-468c-ac17-13c4576c06f0",
   "metadata": {},
   "source": [
    "We can see what the training looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93b44a-8c9d-47ec-ab28-c5adba65d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(L(learn.recorder.values).itemgot(2));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f71eb-6e54-470d-a9d3-9b7739941119",
   "metadata": {},
   "source": [
    "This allows us to look inside the learner.  \n",
    "There's an attribute we create called recorder that records everything in the learn.fit table.  \n",
    ".itemgot(2) -> gets item number two of the table which is the accuracy.  \n",
    "L class -> where we have itemgot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d94772-b09c-4aaa-8725-8de961dde4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can view"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
